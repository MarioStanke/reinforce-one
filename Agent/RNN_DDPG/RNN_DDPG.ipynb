{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0a87bfa-df1a-4239-b926-afae212223c1",
   "metadata": {},
   "source": [
    "## RNN DDPG  \n",
    "This code is from tf-agents library with minor alterations.  \n",
    "5 Herds 1000 total population:  \n",
    "After training, best av_return is about ~90.000.  \n",
    "Best results with scripted policy are roughly 15.000 (see test_rnn_env.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c06df605-2831-4197-884b-8f547c010fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "# Copyright 2020 The TF-Agents Authors.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "# Lint as: python2, python3\n",
    "r\"\"\"Train and Eval DDPG.\n",
    "\n",
    "To run:\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir $HOME/tmp/ddpg_rnn/dm/CartPole-Balance/ --port 2223 &\n",
    "\n",
    "python tf_agents/agents/ddpg/examples/v2/train_eval_rnn.py \\\n",
    "  --root_dir=$HOME/tmp/ddpg_rnn/dm/CartPole-Balance/ \\\n",
    "  --num_iterations=100000 \\\n",
    "  --alsologtostderr\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "root_dir = '~/Masterarbeit/RNN_DDPG'\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import functools\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "sys.path.insert(1, '/home/jovyan/Masterarbeit/reinforce-one/Environment')\n",
    "\n",
    "from absl import app\n",
    "from absl import logging\n",
    "\n",
    "import gin\n",
    "from six.moves import range\n",
    "import tensorflow as tf  # pylint: disable=g-explicit-tensorflow-version-import\n",
    "\n",
    "from tf_agents.agents.ddpg import actor_rnn_network\n",
    "from tf_agents.agents.ddpg import critic_rnn_network\n",
    "from tf_agents.agents.ddpg import ddpg_agent\n",
    "from tf_agents.drivers import dynamic_episode_driver\n",
    "from tf_agents.environments import suite_dm_control\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.environments import wrappers\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.utils import common\n",
    "\n",
    "import numpy \n",
    "from tf_agents.environments import utils\n",
    "from tf_agents.trajectories.time_step import StepType\n",
    "from tf_agents.trajectories import TimeStep\n",
    "from tf_agents.policies import scripted_py_policy\n",
    "from tf_agents.policies import random_py_policy\n",
    "from tf_agents.policies import policy_saver\n",
    "from tf_agents.metrics import py_metrics\n",
    "from tf_agents.drivers import py_driver\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.networks import sequential\n",
    "from Env import Env\n",
    "\n",
    "from RNN_Env_P2 import Env_P2_N\n",
    "max_episode_length=1000\n",
    "num_herds = 2\n",
    "total_population = 300\n",
    "average_episode_length=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1fbc9a0-4895-4a62-8dff-78f3c86adb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "py_env = Env(num_herds = num_herds, total_population = total_population, fix_episode_length = True, average_episode_length = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "553ea59b-fa66-4809-8632-c777549a4fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_return(environment, policy, num_episodes=50, verbose=False):\n",
    "  total_return = 0.0\n",
    "  cullsteps = 0 \n",
    "  for e in range(num_episodes):\n",
    "\n",
    "    time_step = environment.reset()\n",
    "    if isinstance(policy, scripted_py_policy.ScriptedPyPolicy):\n",
    "        policy_state = policy.get_initial_state() # remember where in the script we were\n",
    "    else:\n",
    "        #print(policy.get_initial_state(batch_size=train_env.batch_size()))\n",
    "        policy_state = policy.get_initial_state(batch_size=1) # other policies without memory\n",
    "    episode_return = 0.0\n",
    "    i=0\n",
    "    while not time_step.is_last():\n",
    "        i+=1\n",
    "        action_step = policy.action(time_step, policy_state)\n",
    "        for i in range (num_herds, num_herds*2):\n",
    "            if action_step.action[0][i] > 0.1:\n",
    "                cullsteps += 1\n",
    "                break\n",
    "        policy_state = action_step.state\n",
    "        time_step = environment.step(action_step.action)\n",
    "\n",
    "        state = None # TF environment from wrapper does not have get_state()\n",
    "        episode_return += time_step.reward\n",
    "        if verbose:\n",
    "            print (f\"episode {e:>2} step{i:>4} action: \", action_step.action, \n",
    "                   \"state=\", state, \"obs=\", time_step.observation, \"reward=\", time_step.reward)\n",
    "    total_return += episode_return\n",
    "\n",
    "  avg_return = total_return / num_episodes\n",
    "  cullsteps /= num_episodes\n",
    "  return avg_return, cullsteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "827353e4-a10d-49ef-9291-c8fa50666524",
   "metadata": {},
   "outputs": [],
   "source": [
    "### @gin.configurable\n",
    "def train_eval(\n",
    "    root_dir,\n",
    "    env_name='cartpole',\n",
    "    task_name='balance',\n",
    "    observations_allowlist='position',\n",
    "    num_iterations=200000,\n",
    "    actor_fc_layers=(400, 300),\n",
    "    actor_output_fc_layers=(100,),\n",
    "    actor_lstm_size=(40,),\n",
    "    critic_obs_fc_layers=(400,),\n",
    "    critic_action_fc_layers=None,\n",
    "    critic_joint_fc_layers=(300,),\n",
    "    critic_output_fc_layers=(100,),\n",
    "    critic_lstm_size=(40,),\n",
    "    # Params for collect\n",
    "    initial_collect_episodes=1,  #1000(me)\n",
    "    collect_episodes_per_iteration=1,    #5(me)\n",
    "    replay_buffer_capacity=10000,\n",
    "    ou_stddev=0.2,\n",
    "    ou_damping=0.15,\n",
    "    # Params for target update\n",
    "    target_update_tau=0.05,\n",
    "    target_update_period=5,\n",
    "    # Params for train\n",
    "    # Params for train\n",
    "    train_steps_per_iteration=200,    #200\n",
    "    batch_size=64,\n",
    "    train_sequence_length=20,    #10\n",
    "    actor_learning_rate=1e-4,\n",
    "    critic_learning_rate=1e-3,\n",
    "    dqda_clipping=None,\n",
    "    td_errors_loss_fn=None,\n",
    "    gamma=0.995,    #.995\n",
    "    reward_scale_factor=1.0,\n",
    "    gradient_clipping=None,\n",
    "    use_tf_functions=True,\n",
    "    # Params for eval\n",
    "    num_eval_episodes=200,    #10\n",
    "    eval_interval=1000,    #1000\n",
    "    # Params for checkpoints, summaries, and logging\n",
    "    log_interval=1000,\n",
    "    summary_interval=1000,\n",
    "    summaries_flush_secs=10,\n",
    "    debug_summaries=True,\n",
    "    summarize_grads_and_vars=True,\n",
    "    eval_metrics_callback=None):\n",
    "\n",
    "  \"\"\"A simple train and eval for DDPG.\"\"\"\n",
    "\n",
    "  best_return = -10000\n",
    "  root_dir = os.path.expanduser(root_dir)\n",
    "  train_dir = os.path.join(root_dir, 'train')\n",
    "  eval_dir = os.path.join(root_dir, 'eval')\n",
    "  policy_dir = os.path.join(root_dir, 'policy')\n",
    "\n",
    "  train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "      train_dir, flush_millis=summaries_flush_secs * 1000)\n",
    "  train_summary_writer.set_as_default()\n",
    "\n",
    "  eval_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "      eval_dir, flush_millis=summaries_flush_secs * 1000)\n",
    "  eval_metrics = [\n",
    "      tf_metrics.AverageReturnMetric(buffer_size=num_eval_episodes),\n",
    "      tf_metrics.AverageEpisodeLengthMetric(buffer_size=num_eval_episodes)\n",
    "  ]\n",
    "\n",
    "  global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "  with tf.compat.v2.summary.record_if(\n",
    "      lambda: tf.math.equal(global_step % summary_interval, 0)):\n",
    "    if observations_allowlist is not None:\n",
    "      env_wrappers = [\n",
    "          functools.partial(\n",
    "              wrappers.FlattenObservationsWrapper,\n",
    "              observations_allowlist=[observations_allowlist])\n",
    "      ]\n",
    "    else:\n",
    "      env_wrappers = []\n",
    "\n",
    "    tf_env = tf_py_environment.TFPyEnvironment(py_env)\n",
    "    eval_tf_env = tf_py_environment.TFPyEnvironment(py_env)\n",
    "\n",
    "    actor_net = actor_rnn_network.ActorRnnNetwork(\n",
    "        tf_env.time_step_spec().observation,\n",
    "        tf_env.action_spec(),\n",
    "        input_fc_layer_params=actor_fc_layers,\n",
    "        lstm_size=actor_lstm_size,\n",
    "        output_fc_layer_params=actor_output_fc_layers)\n",
    "\n",
    "    critic_net_input_specs = (tf_env.time_step_spec().observation,\n",
    "                              tf_env.action_spec())\n",
    "\n",
    "    critic_net = critic_rnn_network.CriticRnnNetwork(\n",
    "        critic_net_input_specs,\n",
    "        observation_fc_layer_params=critic_obs_fc_layers,\n",
    "        action_fc_layer_params=critic_action_fc_layers,\n",
    "        joint_fc_layer_params=critic_joint_fc_layers,\n",
    "        lstm_size=critic_lstm_size,\n",
    "        output_fc_layer_params=critic_output_fc_layers,\n",
    "    )\n",
    "\n",
    "    tf_agent = ddpg_agent.DdpgAgent(\n",
    "        tf_env.time_step_spec(),\n",
    "        tf_env.action_spec(),\n",
    "        actor_network=actor_net,\n",
    "        critic_network=critic_net,\n",
    "        actor_optimizer=tf.compat.v1.train.AdamOptimizer(\n",
    "            learning_rate=actor_learning_rate),\n",
    "        critic_optimizer=tf.compat.v1.train.AdamOptimizer(\n",
    "            learning_rate=critic_learning_rate),\n",
    "        ou_stddev=ou_stddev,\n",
    "        ou_damping=ou_damping,\n",
    "        target_update_tau=target_update_tau,\n",
    "        target_update_period=target_update_period,\n",
    "        dqda_clipping=dqda_clipping,\n",
    "        td_errors_loss_fn=td_errors_loss_fn,\n",
    "        gamma=gamma,\n",
    "        reward_scale_factor=reward_scale_factor,\n",
    "        gradient_clipping=gradient_clipping,\n",
    "        debug_summaries=debug_summaries,\n",
    "        summarize_grads_and_vars=summarize_grads_and_vars,\n",
    "        train_step_counter=global_step)\n",
    "    tf_agent.initialize()\n",
    "\n",
    "    train_metrics = [\n",
    "        tf_metrics.NumberOfEpisodes(),\n",
    "        tf_metrics.EnvironmentSteps(),\n",
    "        tf_metrics.AverageReturnMetric(),\n",
    "        tf_metrics.AverageEpisodeLengthMetric(),\n",
    "    ]\n",
    "\n",
    "    eval_policy = tf_agent.policy\n",
    "    collect_policy = tf_agent.collect_policy\n",
    "    \n",
    "    saver = policy_saver.PolicySaver(eval_policy)\n",
    "\n",
    "    replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "        tf_agent.collect_data_spec,\n",
    "        batch_size=tf_env.batch_size,\n",
    "        max_length=replay_buffer_capacity)\n",
    "\n",
    "    initial_collect_driver = dynamic_episode_driver.DynamicEpisodeDriver(\n",
    "        tf_env,\n",
    "        collect_policy,\n",
    "        observers=[replay_buffer.add_batch] + train_metrics,\n",
    "        num_episodes=initial_collect_episodes)\n",
    "\n",
    "    collect_driver = dynamic_episode_driver.DynamicEpisodeDriver(\n",
    "        tf_env,\n",
    "        collect_policy,\n",
    "        observers=[replay_buffer.add_batch] + train_metrics,\n",
    "        num_episodes=collect_episodes_per_iteration)\n",
    "\n",
    "    if use_tf_functions:\n",
    "      initial_collect_driver.run = common.function(initial_collect_driver.run)\n",
    "      collect_driver.run = common.function(collect_driver.run)\n",
    "      tf_agent.train = common.function(tf_agent.train)\n",
    "\n",
    "    # Collect initial replay data.\n",
    "    logging.info(\n",
    "        'Initializing replay buffer by collecting experience for %d episodes '\n",
    "        'with a random policy.', initial_collect_episodes)\n",
    "    initial_collect_driver.run()\n",
    "\n",
    "    results = metric_utils.eager_compute(\n",
    "        eval_metrics,\n",
    "        eval_tf_env,\n",
    "        eval_policy,\n",
    "        num_episodes=num_eval_episodes,\n",
    "        train_step=global_step,\n",
    "        summary_writer=eval_summary_writer,\n",
    "        summary_prefix='Metrics',\n",
    "    )\n",
    "    if eval_metrics_callback is not None:\n",
    "      eval_metrics_callback(results, global_step.numpy())\n",
    "    metric_utils.log_metrics(eval_metrics)\n",
    "\n",
    "    time_step = None\n",
    "    policy_state = collect_policy.get_initial_state(tf_env.batch_size)\n",
    "\n",
    "    timed_at_step = global_step.numpy()\n",
    "    time_acc = 0\n",
    "\n",
    "    # Dataset generates trajectories with shape [BxTx...]\n",
    "    dataset = replay_buffer.as_dataset(\n",
    "        num_parallel_calls=3,\n",
    "        sample_batch_size=batch_size,\n",
    "        num_steps=train_sequence_length + 1).prefetch(3)\n",
    "    iterator = iter(dataset)\n",
    "\n",
    "    def train_step():\n",
    "      experience, _ = next(iterator)\n",
    "      return tf_agent.train(experience)\n",
    "\n",
    "    if use_tf_functions:\n",
    "      train_step = common.function(train_step)\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "      start_time = time.time()\n",
    "      time_step, policy_state = collect_driver.run(\n",
    "          time_step=time_step,\n",
    "          policy_state=policy_state,\n",
    "      )\n",
    "      for _ in range(train_steps_per_iteration):\n",
    "        train_loss = train_step()\n",
    "      time_acc += time.time() - start_time\n",
    "\n",
    "      if global_step.numpy() % log_interval == 0:\n",
    "        logging.info('step = %d, loss = %f', global_step.numpy(),\n",
    "                     train_loss.loss)\n",
    "        steps_per_sec = (global_step.numpy() - timed_at_step) / time_acc\n",
    "        logging.info('%.3f steps/sec', steps_per_sec)\n",
    "        tf.compat.v2.summary.scalar(\n",
    "            name='global_steps_per_sec', data=steps_per_sec, step=global_step)\n",
    "        timed_at_step = global_step.numpy()\n",
    "        time_acc = 0\n",
    "\n",
    "      for train_metric in train_metrics:\n",
    "        train_metric.tf_summaries(\n",
    "            train_step=global_step, step_metrics=train_metrics[:2])\n",
    "\n",
    "      if global_step.numpy() % eval_interval == 0:\n",
    "        results = metric_utils.eager_compute(\n",
    "            eval_metrics,\n",
    "            eval_tf_env,\n",
    "            eval_policy,\n",
    "            num_episodes=num_eval_episodes,\n",
    "            train_step=global_step,\n",
    "            summary_writer=eval_summary_writer,\n",
    "            summary_prefix='Metrics',\n",
    "        )\n",
    "        if eval_metrics_callback is not None:\n",
    "          eval_metrics_callback(results, global_step.numpy())\n",
    "        metric_utils.log_metrics(eval_metrics)\n",
    "        avg_return, cullsteps = compute_avg_return(eval_tf_env, eval_policy, num_episodes=100, verbose=False)\n",
    "        print('step {0}: average return = {1:.1f} cullsteps = {2:.1f}'.format(global_step.numpy(), \n",
    "                                                                                avg_return.numpy().item(), cullsteps))\n",
    "        if avg_return > best_return:\n",
    "            if avg_return > -300:\n",
    "                best_return = avg_return\n",
    "                print('Final best return: ', best_return)\n",
    "                saver.save(os.path.join(policy_dir, str(global_step.numpy())))\n",
    "                break\n",
    "            else:\n",
    "                best_return = avg_return\n",
    "                print('New best return: ', best_return)\n",
    "                saver.save(os.path.join(policy_dir, str(global_step.numpy())))\n",
    "        elif (70000 <= global_step.numpy() <= 80000):\n",
    "            best_return = -14000\n",
    "        elif (100000 <= global_step.numpy() <= 130000):\n",
    "            best_return = -14000\n",
    "            \n",
    "\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c098712-8656-4607-9014-a1a1d4710bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.9/site-packages/tensorflow/python/data/experimental/ops/counter.py:66: scan (from tensorflow.python.data.experimental.ops.scan_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.scan(...) instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.9/site-packages/tensorflow/python/data/experimental/ops/counter.py:66: scan (from tensorflow.python.data.experimental.ops.scan_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.scan(...) instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:382: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:382: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 8 calls to <bound method DynamicEpisodeDriver.run of <tf_agents.drivers.dynamic_episode_driver.DynamicEpisodeDriver object at 0x7fd32c401cd0>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 8 calls to <bound method DynamicEpisodeDriver.run of <tf_agents.drivers.dynamic_episode_driver.DynamicEpisodeDriver object at 0x7fd32c401cd0>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1000: average return = -44524.4 cullsteps = 0.0\n",
      "step 2000: average return = -43560.8 cullsteps = 5.0\n",
      "step 3000: average return = -43654.4 cullsteps = 2.0\n",
      "step 4000: average return = -45961.1 cullsteps = 0.0\n",
      "step 5000: average return = -42653.5 cullsteps = 2.0\n",
      "step 6000: average return = -39595.1 cullsteps = 3.0\n",
      "step 7000: average return = -40563.2 cullsteps = 3.0\n",
      "step 8000: average return = -39789.9 cullsteps = 4.0\n",
      "step 9000: average return = -39123.3 cullsteps = 5.0\n",
      "step 10000: average return = -42153.0 cullsteps = 5.0\n",
      "step 11000: average return = -42511.1 cullsteps = 5.0\n",
      "step 12000: average return = -17100.2 cullsteps = 54.3\n",
      "step 13000: average return = -12619.6 cullsteps = 63.2\n",
      "step 14000: average return = -11497.6 cullsteps = 50.5\n",
      "step 15000: average return = -19375.7 cullsteps = 37.1\n",
      "step 16000: average return = -24350.3 cullsteps = 35.1\n",
      "step 17000: average return = -11892.5 cullsteps = 41.7\n",
      "step 18000: average return = -11707.7 cullsteps = 45.0\n",
      "step 19000: average return = -11903.3 cullsteps = 50.5\n",
      "step 20000: average return = -11982.1 cullsteps = 61.2\n",
      "step 21000: average return = -11676.4 cullsteps = 45.7\n",
      "step 22000: average return = -11686.9 cullsteps = 43.1\n",
      "step 23000: average return = -12931.1 cullsteps = 41.1\n",
      "step 24000: average return = -11323.2 cullsteps = 34.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 25000: average return = -9730.4 cullsteps = 36.3\n",
      "New best return:  tf.Tensor([-9730.371], shape=(1,), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/25000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/25000/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 26000: average return = -10422.7 cullsteps = 38.9\n",
      "step 27000: average return = -10772.4 cullsteps = 43.6\n",
      "step 28000: average return = -10930.4 cullsteps = 43.0\n",
      "step 29000: average return = -10971.6 cullsteps = 45.1\n",
      "step 30000: average return = -11452.3 cullsteps = 40.2\n",
      "step 31000: average return = -11458.1 cullsteps = 38.4\n",
      "step 32000: average return = -9968.4 cullsteps = 32.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 33000: average return = -9532.5 cullsteps = 31.5\n",
      "New best return:  tf.Tensor([-9532.468], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/33000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/33000/assets\n",
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 34000: average return = -9345.0 cullsteps = 36.1\n",
      "New best return:  tf.Tensor([-9345.019], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/34000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/34000/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 35000: average return = -9407.1 cullsteps = 36.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 36000: average return = -9247.0 cullsteps = 28.0\n",
      "New best return:  tf.Tensor([-9247.004], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/36000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/36000/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 37000: average return = -9636.6 cullsteps = 27.6\n",
      "step 38000: average return = -9821.8 cullsteps = 27.6\n",
      "step 39000: average return = -9921.7 cullsteps = 23.4\n",
      "step 40000: average return = -9971.1 cullsteps = 27.7\n",
      "step 41000: average return = -10033.6 cullsteps = 22.0\n",
      "step 42000: average return = -10740.6 cullsteps = 36.4\n",
      "step 43000: average return = -9843.5 cullsteps = 28.4\n",
      "step 44000: average return = -10252.1 cullsteps = 31.5\n",
      "step 45000: average return = -10277.2 cullsteps = 34.4\n",
      "step 46000: average return = -12990.0 cullsteps = 58.9\n",
      "step 47000: average return = -17788.9 cullsteps = 76.9\n",
      "step 48000: average return = -12431.2 cullsteps = 72.6\n",
      "step 49000: average return = -11726.0 cullsteps = 45.0\n",
      "step 50000: average return = -13124.2 cullsteps = 29.9\n",
      "step 51000: average return = -11075.9 cullsteps = 29.5\n",
      "step 52000: average return = -11434.1 cullsteps = 39.1\n",
      "step 53000: average return = -11040.4 cullsteps = 43.3\n",
      "step 54000: average return = -12739.3 cullsteps = 43.8\n",
      "step 55000: average return = -12961.7 cullsteps = 33.0\n",
      "step 56000: average return = -11488.8 cullsteps = 30.7\n",
      "step 57000: average return = -11087.4 cullsteps = 33.6\n",
      "step 58000: average return = -13284.5 cullsteps = 29.0\n",
      "step 59000: average return = -12236.9 cullsteps = 25.0\n",
      "step 60000: average return = -12362.7 cullsteps = 34.5\n",
      "step 61000: average return = -13800.0 cullsteps = 36.5\n",
      "step 62000: average return = -13698.4 cullsteps = 48.5\n",
      "step 63000: average return = -12155.1 cullsteps = 39.7\n",
      "step 64000: average return = -13415.2 cullsteps = 44.6\n",
      "step 65000: average return = -12852.7 cullsteps = 49.1\n",
      "step 66000: average return = -13925.6 cullsteps = 39.7\n",
      "step 67000: average return = -17012.3 cullsteps = 38.0\n",
      "step 68000: average return = -15094.7 cullsteps = 34.5\n",
      "step 69000: average return = -15922.7 cullsteps = 32.3\n",
      "step 70000: average return = -16046.7 cullsteps = 29.1\n",
      "step 71000: average return = -14658.3 cullsteps = 40.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 72000: average return = -13817.8 cullsteps = 37.1\n",
      "New best return:  tf.Tensor([-13817.782], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/72000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/72000/assets\n",
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 73000: average return = -11134.8 cullsteps = 31.8\n",
      "New best return:  tf.Tensor([-11134.838], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/73000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/73000/assets\n",
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 74000: average return = -10994.7 cullsteps = 37.6\n",
      "New best return:  tf.Tensor([-10994.746], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/74000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/74000/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 75000: average return = -12385.7 cullsteps = 39.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 76000: average return = -13795.1 cullsteps = 80.7\n",
      "New best return:  tf.Tensor([-13795.105], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/76000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/76000/assets\n",
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 77000: average return = -11880.7 cullsteps = 53.0\n",
      "New best return:  tf.Tensor([-11880.695], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/77000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/77000/assets\n",
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 78000: average return = -11252.1 cullsteps = 48.2\n",
      "New best return:  tf.Tensor([-11252.104], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/78000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/78000/assets\n",
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 79000: average return = -10421.8 cullsteps = 41.7\n",
      "New best return:  tf.Tensor([-10421.787], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/79000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/79000/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 80000: average return = -10783.0 cullsteps = 40.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 81000: average return = -10998.6 cullsteps = 38.5\n",
      "New best return:  tf.Tensor([-10998.588], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/81000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/81000/assets\n",
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 82000: average return = -10581.7 cullsteps = 49.6\n",
      "New best return:  tf.Tensor([-10581.74], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/82000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/82000/assets\n",
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 83000: average return = -10003.2 cullsteps = 46.6\n",
      "New best return:  tf.Tensor([-10003.169], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/83000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/83000/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 84000: average return = -10087.1 cullsteps = 46.6\n",
      "step 85000: average return = -10433.4 cullsteps = 45.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 86000: average return = -9981.4 cullsteps = 43.7\n",
      "New best return:  tf.Tensor([-9981.443], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/86000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/86000/assets\n",
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 87000: average return = -9561.0 cullsteps = 40.9\n",
      "New best return:  tf.Tensor([-9561.001], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/87000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/87000/assets\n",
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 88000: average return = -8774.0 cullsteps = 29.8\n",
      "New best return:  tf.Tensor([-8774.021], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/88000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/88000/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 89000: average return = -9412.2 cullsteps = 32.3\n",
      "step 90000: average return = -10537.5 cullsteps = 38.7\n",
      "step 91000: average return = -10448.9 cullsteps = 46.1\n",
      "step 92000: average return = -9928.0 cullsteps = 30.5\n",
      "step 93000: average return = -11310.0 cullsteps = 27.8\n",
      "step 94000: average return = -11389.8 cullsteps = 27.1\n",
      "step 95000: average return = -12508.6 cullsteps = 32.9\n",
      "step 96000: average return = -10804.0 cullsteps = 34.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 97000: average return = -8773.1 cullsteps = 38.9\n",
      "New best return:  tf.Tensor([-8773.056], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/97000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/97000/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 98000: average return = -8873.8 cullsteps = 50.5\n",
      "step 99000: average return = -8987.5 cullsteps = 44.7\n",
      "step 100000: average return = -9359.6 cullsteps = 26.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 101000: average return = -9575.5 cullsteps = 26.9\n",
      "New best return:  tf.Tensor([-9575.45], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/101000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/101000/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 102000: average return = -10008.9 cullsteps = 32.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 103000: average return = -10146.2 cullsteps = 34.8\n",
      "New best return:  tf.Tensor([-10146.154], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/103000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/103000/assets\n",
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 104000: average return = -9941.8 cullsteps = 30.9\n",
      "New best return:  tf.Tensor([-9941.825], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/104000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/104000/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 105000: average return = -10254.4 cullsteps = 36.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 106000: average return = -12494.0 cullsteps = 33.6\n",
      "New best return:  tf.Tensor([-12493.954], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/106000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/106000/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 107000: average return = -12802.9 cullsteps = 32.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 108000: average return = -13743.2 cullsteps = 32.1\n",
      "New best return:  tf.Tensor([-13743.2], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/108000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/108000/assets\n",
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 109000: average return = -11646.0 cullsteps = 38.1\n",
      "New best return:  tf.Tensor([-11645.972], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/109000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/109000/assets\n",
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 110000: average return = -9772.2 cullsteps = 38.8\n",
      "New best return:  tf.Tensor([-9772.229], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/110000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/110000/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 111000: average return = -10881.9 cullsteps = 40.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 112000: average return = -10799.9 cullsteps = 43.1\n",
      "New best return:  tf.Tensor([-10799.867], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/112000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/112000/assets\n",
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 113000: average return = -10392.4 cullsteps = 47.7\n",
      "New best return:  tf.Tensor([-10392.381], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/113000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/113000/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 114000: average return = -10910.6 cullsteps = 40.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 115000: average return = -12151.3 cullsteps = 33.4\n",
      "New best return:  tf.Tensor([-12151.295], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/115000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/115000/assets\n",
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 116000: average return = -10050.0 cullsteps = 42.9\n",
      "New best return:  tf.Tensor([-10049.988], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/116000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/116000/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 117000: average return = -11251.7 cullsteps = 43.7\n",
      "step 118000: average return = -14042.2 cullsteps = 31.7\n",
      "step 119000: average return = -21683.3 cullsteps = 18.5\n",
      "step 120000: average return = -14036.3 cullsteps = 29.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 121000: average return = -10782.7 cullsteps = 30.9\n",
      "New best return:  tf.Tensor([-10782.707], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/121000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/121000/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 122000: average return = -31650.7 cullsteps = 8.1\n",
      "step 123000: average return = -28146.9 cullsteps = 9.5\n",
      "step 124000: average return = -29288.8 cullsteps = 8.5\n",
      "step 125000: average return = -19581.2 cullsteps = 19.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 126000: average return = -13790.0 cullsteps = 32.7\n",
      "New best return:  tf.Tensor([-13789.977], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/126000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/126000/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 127000: average return = -15983.4 cullsteps = 37.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 128000: average return = -12245.8 cullsteps = 45.8\n",
      "New best return:  tf.Tensor([-12245.77], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/128000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/128000/assets\n",
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 129000: average return = -11707.8 cullsteps = 36.3\n",
      "New best return:  tf.Tensor([-11707.8], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/129000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/129000/assets\n",
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 130000: average return = -10075.0 cullsteps = 36.0\n",
      "New best return:  tf.Tensor([-10074.97], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/130000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/130000/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 131000: average return = -13559.0 cullsteps = 26.1\n",
      "step 132000: average return = -10498.5 cullsteps = 29.1\n",
      "step 133000: average return = -10619.6 cullsteps = 31.0\n",
      "step 134000: average return = -10961.7 cullsteps = 32.3\n",
      "step 135000: average return = -11540.0 cullsteps = 33.5\n",
      "step 136000: average return = -11949.0 cullsteps = 37.5\n",
      "step 137000: average return = -11484.5 cullsteps = 34.1\n",
      "step 138000: average return = -11670.1 cullsteps = 44.7\n",
      "step 139000: average return = -12130.0 cullsteps = 51.4\n",
      "step 140000: average return = -10426.5 cullsteps = 39.6\n",
      "step 141000: average return = -11765.1 cullsteps = 43.9\n",
      "step 142000: average return = -11463.5 cullsteps = 40.1\n",
      "step 143000: average return = -12219.2 cullsteps = 49.1\n",
      "step 144000: average return = -12452.3 cullsteps = 71.4\n",
      "step 145000: average return = -11347.2 cullsteps = 55.5\n",
      "step 146000: average return = -10514.5 cullsteps = 37.8\n",
      "step 147000: average return = -12005.6 cullsteps = 42.3\n",
      "step 148000: average return = -15772.0 cullsteps = 21.9\n",
      "step 149000: average return = -12647.0 cullsteps = 32.6\n",
      "step 150000: average return = -11152.1 cullsteps = 35.1\n",
      "step 151000: average return = -12525.9 cullsteps = 32.5\n",
      "step 152000: average return = -13864.1 cullsteps = 33.0\n",
      "step 153000: average return = -10648.8 cullsteps = 35.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 154000: average return = -9930.9 cullsteps = 41.7\n",
      "New best return:  tf.Tensor([-9930.911], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/154000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/154000/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 155000: average return = -12772.0 cullsteps = 35.0\n",
      "step 156000: average return = -14872.1 cullsteps = 35.9\n",
      "step 157000: average return = -13917.1 cullsteps = 38.0\n",
      "step 158000: average return = -13480.2 cullsteps = 40.6\n",
      "step 159000: average return = -13495.2 cullsteps = 35.4\n",
      "step 160000: average return = -11860.3 cullsteps = 33.9\n",
      "step 161000: average return = -12329.1 cullsteps = 35.0\n",
      "step 162000: average return = -11352.7 cullsteps = 37.7\n",
      "step 163000: average return = -11531.0 cullsteps = 32.2\n",
      "step 164000: average return = -11497.5 cullsteps = 55.0\n",
      "step 165000: average return = -11132.7 cullsteps = 51.9\n",
      "step 166000: average return = -10838.2 cullsteps = 49.4\n",
      "step 167000: average return = -11499.6 cullsteps = 32.0\n",
      "step 168000: average return = -10048.9 cullsteps = 34.2\n",
      "step 169000: average return = -10114.7 cullsteps = 41.5\n",
      "step 170000: average return = -10842.1 cullsteps = 44.7\n",
      "step 171000: average return = -11687.6 cullsteps = 18.1\n",
      "step 172000: average return = -12917.6 cullsteps = 20.3\n",
      "step 173000: average return = -13577.1 cullsteps = 23.1\n",
      "step 174000: average return = -13078.7 cullsteps = 20.9\n",
      "step 175000: average return = -13876.0 cullsteps = 19.4\n",
      "step 176000: average return = -13512.7 cullsteps = 22.8\n",
      "step 177000: average return = -13043.2 cullsteps = 24.2\n",
      "step 178000: average return = -11740.6 cullsteps = 29.5\n",
      "step 179000: average return = -12541.5 cullsteps = 33.6\n",
      "step 180000: average return = -13444.6 cullsteps = 41.9\n",
      "step 181000: average return = -13534.2 cullsteps = 57.9\n",
      "step 182000: average return = -13757.5 cullsteps = 40.4\n",
      "step 183000: average return = -15380.7 cullsteps = 23.8\n",
      "step 184000: average return = -15042.6 cullsteps = 40.0\n",
      "step 185000: average return = -17162.5 cullsteps = 40.1\n",
      "step 186000: average return = -14297.6 cullsteps = 46.7\n",
      "step 187000: average return = -13447.0 cullsteps = 25.8\n",
      "step 188000: average return = -13368.4 cullsteps = 27.0\n",
      "step 189000: average return = -12970.8 cullsteps = 25.0\n",
      "step 190000: average return = -12389.4 cullsteps = 23.9\n",
      "step 191000: average return = -12934.2 cullsteps = 23.0\n",
      "step 192000: average return = -12754.3 cullsteps = 22.2\n",
      "step 193000: average return = -11365.2 cullsteps = 21.8\n",
      "step 194000: average return = -12160.2 cullsteps = 23.7\n",
      "step 195000: average return = -14673.0 cullsteps = 25.1\n",
      "step 196000: average return = -14445.9 cullsteps = 24.0\n",
      "step 197000: average return = -17213.0 cullsteps = 18.2\n",
      "step 198000: average return = -18869.8 cullsteps = 16.6\n",
      "step 199000: average return = -16403.9 cullsteps = 25.6\n",
      "step 200000: average return = -18190.5 cullsteps = 19.5\n",
      "step 201000: average return = -18562.2 cullsteps = 20.3\n",
      "step 202000: average return = -16296.6 cullsteps = 17.7\n",
      "step 203000: average return = -16202.6 cullsteps = 21.0\n",
      "step 204000: average return = -14158.1 cullsteps = 39.6\n",
      "step 205000: average return = -13617.8 cullsteps = 31.8\n",
      "step 206000: average return = -16054.6 cullsteps = 31.4\n",
      "step 207000: average return = -15593.7 cullsteps = 30.5\n",
      "step 208000: average return = -20787.9 cullsteps = 18.5\n",
      "step 209000: average return = -24607.8 cullsteps = 15.3\n",
      "step 210000: average return = -22271.8 cullsteps = 25.3\n",
      "step 211000: average return = -29882.9 cullsteps = 14.6\n",
      "step 212000: average return = -29392.5 cullsteps = 9.5\n",
      "step 213000: average return = -33515.0 cullsteps = 6.5\n",
      "step 214000: average return = -21150.8 cullsteps = 19.1\n",
      "step 215000: average return = -36044.1 cullsteps = 12.4\n",
      "step 216000: average return = -25515.7 cullsteps = 18.5\n",
      "step 217000: average return = -11311.9 cullsteps = 21.8\n",
      "step 218000: average return = -13918.3 cullsteps = 22.8\n",
      "step 219000: average return = -13120.9 cullsteps = 23.2\n",
      "step 220000: average return = -10334.9 cullsteps = 39.5\n",
      "step 221000: average return = -10736.9 cullsteps = 56.7\n",
      "step 222000: average return = -14270.7 cullsteps = 35.5\n",
      "step 223000: average return = -10561.0 cullsteps = 22.9\n",
      "step 224000: average return = -13199.0 cullsteps = 28.6\n",
      "step 225000: average return = -12993.9 cullsteps = 26.1\n",
      "step 226000: average return = -11597.9 cullsteps = 26.6\n",
      "step 227000: average return = -12739.3 cullsteps = 28.9\n",
      "step 228000: average return = -12095.8 cullsteps = 50.9\n",
      "step 229000: average return = -11371.3 cullsteps = 49.5\n",
      "step 230000: average return = -14079.1 cullsteps = 78.5\n",
      "step 231000: average return = -20182.9 cullsteps = 30.9\n",
      "step 232000: average return = -25480.2 cullsteps = 16.3\n",
      "step 233000: average return = -18193.4 cullsteps = 44.4\n",
      "step 234000: average return = -18774.2 cullsteps = 34.0\n",
      "step 235000: average return = -21988.9 cullsteps = 19.2\n",
      "step 236000: average return = -18362.4 cullsteps = 22.9\n",
      "step 237000: average return = -17891.0 cullsteps = 25.6\n",
      "step 238000: average return = -14252.7 cullsteps = 32.9\n",
      "step 239000: average return = -16083.1 cullsteps = 32.8\n",
      "step 240000: average return = -25998.0 cullsteps = 16.7\n",
      "step 241000: average return = -20000.3 cullsteps = 28.8\n",
      "step 242000: average return = -23569.6 cullsteps = 16.1\n",
      "step 243000: average return = -25607.2 cullsteps = 8.5\n",
      "step 244000: average return = -16329.9 cullsteps = 27.3\n",
      "step 245000: average return = -18315.2 cullsteps = 22.2\n",
      "step 246000: average return = -16466.7 cullsteps = 22.3\n",
      "step 247000: average return = -12006.0 cullsteps = 32.2\n",
      "step 248000: average return = -10577.3 cullsteps = 34.4\n",
      "step 249000: average return = -10212.4 cullsteps = 42.6\n",
      "step 250000: average return = -10314.1 cullsteps = 36.0\n",
      "step 251000: average return = -13298.5 cullsteps = 26.5\n",
      "step 252000: average return = -11959.8 cullsteps = 34.8\n",
      "step 253000: average return = -15116.6 cullsteps = 40.4\n",
      "step 254000: average return = -29840.7 cullsteps = 11.0\n",
      "step 255000: average return = -17458.2 cullsteps = 26.3\n",
      "step 256000: average return = -11174.3 cullsteps = 47.9\n",
      "step 257000: average return = -11858.0 cullsteps = 45.6\n",
      "step 258000: average return = -14412.0 cullsteps = 44.3\n",
      "step 259000: average return = -14825.8 cullsteps = 54.7\n",
      "step 260000: average return = -14487.6 cullsteps = 68.9\n",
      "step 261000: average return = -13793.7 cullsteps = 79.5\n",
      "step 262000: average return = -17558.1 cullsteps = 72.9\n",
      "step 263000: average return = -18744.1 cullsteps = 75.8\n",
      "step 264000: average return = -18060.5 cullsteps = 68.6\n",
      "step 265000: average return = -16154.0 cullsteps = 53.4\n",
      "step 266000: average return = -13934.6 cullsteps = 25.0\n",
      "step 267000: average return = -13335.1 cullsteps = 45.0\n",
      "step 268000: average return = -10906.5 cullsteps = 27.6\n",
      "step 269000: average return = -10446.4 cullsteps = 33.6\n",
      "step 270000: average return = -11238.8 cullsteps = 39.9\n",
      "step 271000: average return = -11262.9 cullsteps = 41.0\n",
      "step 272000: average return = -15069.3 cullsteps = 84.8\n",
      "step 273000: average return = -14239.2 cullsteps = 88.4\n",
      "step 274000: average return = -14305.8 cullsteps = 65.5\n",
      "step 275000: average return = -11896.4 cullsteps = 39.0\n",
      "step 276000: average return = -13744.0 cullsteps = 28.5\n",
      "step 277000: average return = -12377.0 cullsteps = 31.6\n",
      "step 278000: average return = -12116.6 cullsteps = 25.6\n",
      "step 279000: average return = -14640.8 cullsteps = 22.2\n",
      "step 280000: average return = -15291.2 cullsteps = 20.6\n",
      "step 281000: average return = -18434.2 cullsteps = 16.1\n",
      "step 282000: average return = -35153.8 cullsteps = 4.8\n",
      "step 283000: average return = -28029.8 cullsteps = 6.9\n",
      "step 284000: average return = -34327.3 cullsteps = 4.1\n",
      "step 285000: average return = -41436.6 cullsteps = 3.3\n",
      "step 286000: average return = -37203.3 cullsteps = 5.4\n",
      "step 287000: average return = -41536.3 cullsteps = 1.1\n",
      "step 288000: average return = -28211.6 cullsteps = 17.7\n",
      "step 289000: average return = -18925.1 cullsteps = 30.5\n",
      "step 290000: average return = -11395.6 cullsteps = 41.3\n",
      "step 291000: average return = -27580.7 cullsteps = 10.5\n",
      "step 292000: average return = -22753.0 cullsteps = 19.6\n",
      "step 293000: average return = -15120.5 cullsteps = 24.9\n",
      "step 294000: average return = -29043.6 cullsteps = 15.2\n",
      "step 295000: average return = -19502.7 cullsteps = 23.0\n",
      "step 296000: average return = -12075.5 cullsteps = 36.6\n",
      "step 297000: average return = -13837.1 cullsteps = 39.4\n",
      "step 298000: average return = -14605.5 cullsteps = 45.1\n",
      "step 299000: average return = -12868.9 cullsteps = 41.8\n",
      "step 300000: average return = -15312.1 cullsteps = 28.1\n",
      "step 301000: average return = -12806.4 cullsteps = 31.5\n",
      "step 302000: average return = -17404.2 cullsteps = 24.4\n",
      "step 303000: average return = -16661.8 cullsteps = 23.9\n",
      "step 304000: average return = -17159.3 cullsteps = 21.3\n",
      "step 305000: average return = -16223.0 cullsteps = 21.2\n",
      "step 306000: average return = -13896.3 cullsteps = 27.8\n",
      "step 307000: average return = -16020.0 cullsteps = 26.3\n",
      "step 308000: average return = -24382.9 cullsteps = 16.2\n",
      "step 309000: average return = -21945.8 cullsteps = 19.8\n",
      "step 310000: average return = -15035.0 cullsteps = 70.0\n",
      "step 311000: average return = -16718.1 cullsteps = 69.0\n",
      "step 312000: average return = -20309.2 cullsteps = 33.1\n",
      "step 313000: average return = -23340.0 cullsteps = 24.1\n",
      "step 314000: average return = -23473.0 cullsteps = 18.3\n",
      "step 315000: average return = -28367.8 cullsteps = 11.6\n",
      "step 316000: average return = -14546.4 cullsteps = 59.6\n",
      "step 317000: average return = -20089.2 cullsteps = 22.7\n",
      "step 318000: average return = -18070.3 cullsteps = 23.1\n",
      "step 319000: average return = -23451.0 cullsteps = 13.4\n",
      "step 320000: average return = -16426.1 cullsteps = 16.1\n",
      "step 321000: average return = -17422.0 cullsteps = 16.8\n",
      "step 322000: average return = -16446.8 cullsteps = 18.9\n",
      "step 323000: average return = -11357.7 cullsteps = 31.4\n",
      "step 324000: average return = -11018.4 cullsteps = 35.7\n",
      "step 325000: average return = -11966.7 cullsteps = 37.9\n",
      "step 326000: average return = -12883.4 cullsteps = 38.0\n",
      "step 327000: average return = -12444.3 cullsteps = 26.7\n",
      "step 328000: average return = -13258.3 cullsteps = 26.8\n",
      "step 329000: average return = -10699.7 cullsteps = 27.5\n",
      "step 330000: average return = -11152.2 cullsteps = 30.9\n",
      "step 331000: average return = -10918.2 cullsteps = 27.0\n",
      "step 332000: average return = -10653.7 cullsteps = 23.9\n",
      "step 333000: average return = -11929.7 cullsteps = 25.3\n",
      "step 334000: average return = -11697.3 cullsteps = 25.2\n",
      "step 335000: average return = -11055.5 cullsteps = 22.5\n",
      "step 336000: average return = -10031.6 cullsteps = 27.1\n",
      "step 337000: average return = -10708.6 cullsteps = 27.5\n",
      "step 338000: average return = -14002.9 cullsteps = 22.6\n",
      "step 339000: average return = -13390.1 cullsteps = 28.5\n",
      "step 340000: average return = -14609.8 cullsteps = 28.7\n",
      "step 341000: average return = -14060.0 cullsteps = 27.5\n",
      "step 342000: average return = -17259.2 cullsteps = 23.6\n",
      "step 343000: average return = -14829.0 cullsteps = 24.9\n",
      "step 344000: average return = -15107.5 cullsteps = 25.3\n",
      "step 345000: average return = -15537.0 cullsteps = 36.6\n",
      "step 346000: average return = -15547.6 cullsteps = 34.8\n",
      "step 347000: average return = -12814.3 cullsteps = 38.6\n",
      "step 348000: average return = -12948.0 cullsteps = 36.8\n",
      "step 349000: average return = -12348.4 cullsteps = 30.5\n",
      "step 350000: average return = -11978.4 cullsteps = 32.2\n",
      "step 351000: average return = -12356.6 cullsteps = 37.3\n",
      "step 352000: average return = -13495.1 cullsteps = 32.8\n",
      "step 353000: average return = -15415.6 cullsteps = 34.3\n",
      "step 354000: average return = -14155.7 cullsteps = 28.4\n",
      "step 355000: average return = -11470.5 cullsteps = 31.5\n",
      "step 356000: average return = -10947.2 cullsteps = 28.8\n",
      "step 357000: average return = -11262.6 cullsteps = 29.0\n",
      "step 358000: average return = -11291.5 cullsteps = 31.6\n",
      "step 359000: average return = -12197.8 cullsteps = 29.1\n",
      "step 360000: average return = -11871.9 cullsteps = 31.1\n",
      "step 361000: average return = -12474.1 cullsteps = 25.8\n",
      "step 362000: average return = -11259.2 cullsteps = 27.4\n",
      "step 363000: average return = -14350.8 cullsteps = 23.6\n",
      "step 364000: average return = -17041.0 cullsteps = 20.0\n",
      "step 365000: average return = -17354.1 cullsteps = 20.6\n",
      "step 366000: average return = -20653.8 cullsteps = 22.5\n",
      "step 367000: average return = -18786.8 cullsteps = 20.8\n",
      "step 368000: average return = -17303.9 cullsteps = 23.7\n",
      "step 369000: average return = -15570.2 cullsteps = 28.6\n",
      "step 370000: average return = -25147.0 cullsteps = 16.1\n",
      "step 371000: average return = -24477.8 cullsteps = 14.2\n",
      "step 372000: average return = -26054.9 cullsteps = 11.6\n",
      "step 373000: average return = -28690.7 cullsteps = 10.4\n",
      "step 374000: average return = -24364.9 cullsteps = 12.4\n",
      "step 375000: average return = -23566.5 cullsteps = 17.0\n",
      "step 376000: average return = -21866.5 cullsteps = 22.9\n",
      "step 377000: average return = -18628.1 cullsteps = 28.2\n",
      "step 378000: average return = -15409.9 cullsteps = 30.8\n",
      "step 379000: average return = -14933.7 cullsteps = 30.0\n",
      "step 380000: average return = -15301.3 cullsteps = 27.1\n",
      "step 381000: average return = -16623.7 cullsteps = 25.9\n",
      "step 382000: average return = -16734.5 cullsteps = 25.6\n",
      "step 383000: average return = -16639.0 cullsteps = 23.9\n",
      "step 384000: average return = -16232.7 cullsteps = 23.4\n",
      "step 385000: average return = -18714.9 cullsteps = 26.2\n",
      "step 386000: average return = -18722.0 cullsteps = 27.9\n",
      "step 387000: average return = -17764.1 cullsteps = 28.7\n",
      "step 388000: average return = -15737.8 cullsteps = 32.9\n",
      "step 389000: average return = -18254.5 cullsteps = 29.1\n",
      "step 390000: average return = -20035.1 cullsteps = 25.3\n",
      "step 391000: average return = -18121.3 cullsteps = 31.6\n",
      "step 392000: average return = -16593.4 cullsteps = 25.8\n",
      "step 393000: average return = -16994.9 cullsteps = 23.3\n",
      "step 394000: average return = -20196.0 cullsteps = 18.1\n",
      "step 395000: average return = -19744.1 cullsteps = 19.1\n",
      "step 396000: average return = -17415.3 cullsteps = 21.8\n",
      "step 397000: average return = -17012.9 cullsteps = 18.5\n",
      "step 398000: average return = -14702.6 cullsteps = 20.0\n",
      "step 399000: average return = -16623.8 cullsteps = 22.0\n",
      "step 400000: average return = -14709.2 cullsteps = 24.0\n",
      "step 401000: average return = -15304.4 cullsteps = 25.0\n",
      "step 402000: average return = -15118.6 cullsteps = 23.8\n",
      "step 403000: average return = -16343.4 cullsteps = 24.1\n",
      "step 404000: average return = -15493.6 cullsteps = 33.9\n",
      "step 405000: average return = -18288.6 cullsteps = 27.7\n",
      "step 406000: average return = -17507.0 cullsteps = 22.1\n",
      "step 407000: average return = -20897.0 cullsteps = 23.1\n",
      "step 408000: average return = -22198.6 cullsteps = 22.8\n",
      "step 409000: average return = -24633.8 cullsteps = 15.7\n",
      "step 410000: average return = -20822.4 cullsteps = 20.1\n",
      "step 411000: average return = -19041.4 cullsteps = 20.1\n",
      "step 412000: average return = -15032.1 cullsteps = 25.3\n",
      "step 413000: average return = -12710.5 cullsteps = 26.5\n",
      "step 414000: average return = -11962.1 cullsteps = 26.3\n",
      "step 415000: average return = -12324.1 cullsteps = 23.8\n",
      "step 416000: average return = -14458.8 cullsteps = 22.4\n",
      "step 417000: average return = -14607.3 cullsteps = 23.2\n",
      "step 418000: average return = -13360.0 cullsteps = 24.5\n",
      "step 419000: average return = -14690.3 cullsteps = 22.6\n",
      "step 420000: average return = -15226.0 cullsteps = 20.7\n",
      "step 421000: average return = -14705.2 cullsteps = 21.4\n",
      "step 422000: average return = -15323.3 cullsteps = 21.8\n",
      "step 423000: average return = -16225.2 cullsteps = 19.4\n",
      "step 424000: average return = -16875.7 cullsteps = 20.1\n",
      "step 425000: average return = -15482.5 cullsteps = 22.0\n",
      "step 426000: average return = -13829.2 cullsteps = 22.4\n",
      "step 427000: average return = -14388.6 cullsteps = 21.8\n",
      "step 428000: average return = -13673.7 cullsteps = 24.7\n",
      "step 429000: average return = -14896.8 cullsteps = 23.8\n",
      "step 430000: average return = -15617.3 cullsteps = 22.9\n",
      "step 431000: average return = -14793.4 cullsteps = 24.2\n",
      "step 432000: average return = -15907.5 cullsteps = 22.3\n",
      "step 433000: average return = -15229.5 cullsteps = 22.9\n",
      "step 434000: average return = -13962.3 cullsteps = 24.0\n",
      "step 435000: average return = -12738.8 cullsteps = 29.5\n",
      "step 436000: average return = -13410.6 cullsteps = 28.0\n",
      "step 437000: average return = -14582.9 cullsteps = 25.3\n",
      "step 438000: average return = -14954.2 cullsteps = 23.5\n",
      "step 439000: average return = -13860.3 cullsteps = 24.6\n",
      "step 440000: average return = -14455.4 cullsteps = 25.7\n",
      "step 441000: average return = -14220.2 cullsteps = 26.3\n",
      "step 442000: average return = -14379.1 cullsteps = 23.9\n",
      "step 443000: average return = -14227.5 cullsteps = 22.3\n",
      "step 444000: average return = -14553.9 cullsteps = 23.1\n",
      "step 445000: average return = -14105.9 cullsteps = 23.1\n",
      "step 446000: average return = -14362.7 cullsteps = 24.0\n",
      "step 447000: average return = -14837.9 cullsteps = 21.7\n",
      "step 448000: average return = -13335.6 cullsteps = 23.5\n",
      "step 449000: average return = -14677.4 cullsteps = 22.4\n",
      "step 450000: average return = -15260.5 cullsteps = 22.2\n",
      "step 451000: average return = -15763.9 cullsteps = 22.4\n",
      "step 452000: average return = -14998.4 cullsteps = 22.1\n",
      "step 453000: average return = -14020.5 cullsteps = 24.6\n",
      "step 454000: average return = -13182.0 cullsteps = 23.6\n",
      "step 455000: average return = -13102.2 cullsteps = 23.7\n",
      "step 456000: average return = -13080.5 cullsteps = 25.6\n",
      "step 457000: average return = -13860.2 cullsteps = 25.2\n",
      "step 458000: average return = -13336.7 cullsteps = 27.9\n",
      "step 459000: average return = -12994.5 cullsteps = 29.8\n",
      "step 460000: average return = -13132.5 cullsteps = 29.0\n",
      "step 461000: average return = -12259.3 cullsteps = 27.3\n",
      "step 462000: average return = -13028.8 cullsteps = 26.6\n",
      "step 463000: average return = -12819.4 cullsteps = 26.6\n",
      "step 464000: average return = -12705.6 cullsteps = 25.2\n",
      "step 465000: average return = -12635.7 cullsteps = 26.5\n",
      "step 466000: average return = -12573.9 cullsteps = 27.1\n",
      "step 467000: average return = -12870.7 cullsteps = 25.9\n",
      "step 468000: average return = -12301.8 cullsteps = 26.4\n",
      "step 469000: average return = -11827.5 cullsteps = 32.4\n",
      "step 470000: average return = -10929.3 cullsteps = 31.5\n",
      "step 471000: average return = -11038.0 cullsteps = 33.8\n",
      "step 472000: average return = -11630.0 cullsteps = 39.2\n",
      "step 473000: average return = -11363.2 cullsteps = 38.2\n",
      "step 474000: average return = -11480.8 cullsteps = 40.8\n",
      "step 475000: average return = -11454.7 cullsteps = 41.0\n",
      "step 476000: average return = -11891.6 cullsteps = 42.1\n",
      "step 477000: average return = -11925.2 cullsteps = 37.9\n",
      "step 478000: average return = -12126.0 cullsteps = 30.3\n",
      "step 479000: average return = -11777.7 cullsteps = 29.4\n",
      "step 480000: average return = -12213.4 cullsteps = 28.1\n",
      "step 481000: average return = -11826.8 cullsteps = 29.2\n",
      "step 482000: average return = -12676.4 cullsteps = 28.5\n",
      "step 483000: average return = -12466.0 cullsteps = 29.5\n",
      "step 484000: average return = -12187.2 cullsteps = 26.9\n",
      "step 485000: average return = -13265.3 cullsteps = 23.1\n",
      "step 486000: average return = -12476.0 cullsteps = 24.9\n",
      "step 487000: average return = -12302.7 cullsteps = 27.0\n",
      "step 488000: average return = -12897.8 cullsteps = 23.1\n"
     ]
    }
   ],
   "source": [
    "train_eval(root_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
