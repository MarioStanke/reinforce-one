{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0a87bfa-df1a-4239-b926-afae212223c1",
   "metadata": {},
   "source": [
    "## RNN DDPG  \n",
    "This code is from tf-agents library with minor alterations.  \n",
    "5 Herds 1000 total population:  \n",
    "After training, best av_return is about ~90.000.  \n",
    "Best results with scripted policy are roughly 15.000 (see test_rnn_env.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9deede77-1eee-4990-b9f0-1bab787a9f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "# Copyright 2020 The TF-Agents Authors.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "# Lint as: python2, python3\n",
    "r\"\"\"Train and Eval DDPG.\n",
    "\n",
    "To run:\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir $HOME/tmp/ddpg_rnn/dm/CartPole-Balance/ --port 2223 &\n",
    "\n",
    "python tf_agents/agents/ddpg/examples/v2/train_eval_rnn.py \\\n",
    "  --root_dir=$HOME/tmp/ddpg_rnn/dm/CartPole-Balance/ \\\n",
    "  --num_iterations=100000 \\\n",
    "  --alsologtostderr\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "root_dir = '~/Masterarbeit/RNN_DDPG'\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import functools\n",
    "import os\n",
    "import time\n",
    "\n",
    "from absl import app\n",
    "from absl import logging\n",
    "\n",
    "import gin\n",
    "from six.moves import range\n",
    "import tensorflow as tf  # pylint: disable=g-explicit-tensorflow-version-import\n",
    "\n",
    "from tf_agents.agents.ddpg import actor_rnn_network\n",
    "from tf_agents.agents.ddpg import critic_rnn_network\n",
    "from tf_agents.agents.ddpg import ddpg_agent\n",
    "from tf_agents.drivers import dynamic_episode_driver\n",
    "from tf_agents.environments import suite_dm_control\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.environments import wrappers\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.utils import common\n",
    "\n",
    "import numpy \n",
    "from tf_agents.environments import utils\n",
    "from tf_agents.trajectories.time_step import StepType\n",
    "from tf_agents.trajectories import TimeStep\n",
    "from tf_agents.policies import scripted_py_policy\n",
    "from tf_agents.policies import random_py_policy\n",
    "from tf_agents.policies import policy_saver\n",
    "from tf_agents.metrics import py_metrics\n",
    "from tf_agents.drivers import py_driver\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.networks import sequential\n",
    "\n",
    "from RNN_Env_P2 import Env_P2_N\n",
    "max_episode_length=1000\n",
    "num_herds = 2\n",
    "total_population = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1fbc9a0-4895-4a62-8dff-78f3c86adb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "py_env = Env_P2_N(num_herds = num_herds, total_population = total_population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "553ea59b-fa66-4809-8632-c777549a4fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_return(environment, policy, num_episodes=50, verbose=False):\n",
    "  total_return = 0.0\n",
    "  cullsteps = 0 \n",
    "  for e in range(num_episodes):\n",
    "\n",
    "    time_step = environment.reset()\n",
    "    if isinstance(policy, scripted_py_policy.ScriptedPyPolicy):\n",
    "        policy_state = policy.get_initial_state() # remember where in the script we were\n",
    "    else:\n",
    "        #print(policy.get_initial_state(batch_size=train_env.batch_size()))\n",
    "        policy_state = policy.get_initial_state(batch_size=1) # other policies without memory\n",
    "    episode_return = 0.0\n",
    "    i=0\n",
    "    while not time_step.is_last():\n",
    "        i+=1\n",
    "        action_step = policy.action(time_step, policy_state)\n",
    "        for i in range (num_herds, num_herds*2):\n",
    "            if action_step.action[0][i] > 0.1:\n",
    "                cullsteps += 1\n",
    "                break\n",
    "        policy_state = action_step.state\n",
    "        time_step = environment.step(action_step.action)\n",
    "\n",
    "        state = None # TF environment from wrapper does not have get_state()\n",
    "        episode_return += time_step.reward\n",
    "        if verbose:\n",
    "            print (f\"episode {e:>2} step{i:>4} action: \", action_step.action, \n",
    "                   \"state=\", state, \"obs=\", time_step.observation, \"reward=\", time_step.reward)\n",
    "    total_return += episode_return\n",
    "\n",
    "  avg_return = total_return / num_episodes\n",
    "  cullsteps /= num_episodes\n",
    "  return avg_return, cullsteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "827353e4-a10d-49ef-9291-c8fa50666524",
   "metadata": {},
   "outputs": [],
   "source": [
    "### @gin.configurable\n",
    "def train_eval(\n",
    "    root_dir,\n",
    "    env_name='cartpole',\n",
    "    task_name='balance',\n",
    "    observations_allowlist='position',\n",
    "    num_iterations=20000,\n",
    "    actor_fc_layers=(400, 300),\n",
    "    actor_output_fc_layers=(100,),\n",
    "    actor_lstm_size=(40,),\n",
    "    critic_obs_fc_layers=(400,),\n",
    "    critic_action_fc_layers=None,\n",
    "    critic_joint_fc_layers=(300,),\n",
    "    critic_output_fc_layers=(100,),\n",
    "    critic_lstm_size=(40,),\n",
    "    # Params for collect\n",
    "    initial_collect_episodes=1000,  #1\n",
    "    collect_episodes_per_iteration=5,    #1\n",
    "    replay_buffer_capacity=10000,\n",
    "    ou_stddev=0.2,\n",
    "    ou_damping=0.15,\n",
    "    # Params for target update\n",
    "    target_update_tau=0.05,\n",
    "    target_update_period=5,\n",
    "    # Params for train\n",
    "    # Params for train\n",
    "    train_steps_per_iteration=100,    #200\n",
    "    batch_size=64,\n",
    "    train_sequence_length=20,    #10\n",
    "    actor_learning_rate=1e-4,\n",
    "    critic_learning_rate=1e-3,\n",
    "    dqda_clipping=None,\n",
    "    td_errors_loss_fn=None,\n",
    "    gamma=0.995,    #.995\n",
    "    reward_scale_factor=1.0,\n",
    "    gradient_clipping=None,\n",
    "    use_tf_functions=True,\n",
    "    # Params for eval\n",
    "    num_eval_episodes=200,    #10\n",
    "    eval_interval=1000,    #1000\n",
    "    # Params for checkpoints, summaries, and logging\n",
    "    log_interval=1000,\n",
    "    summary_interval=1000,\n",
    "    summaries_flush_secs=10,\n",
    "    debug_summaries=True,\n",
    "    summarize_grads_and_vars=True,\n",
    "    eval_metrics_callback=None):\n",
    "\n",
    "  \"\"\"A simple train and eval for DDPG.\"\"\"\n",
    "\n",
    "  best_return = -20000\n",
    "  root_dir = os.path.expanduser(root_dir)\n",
    "  train_dir = os.path.join(root_dir, 'train')\n",
    "  eval_dir = os.path.join(root_dir, 'eval')\n",
    "  policy_dir = os.path.join(root_dir, 'policy')\n",
    "\n",
    "  train_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "      train_dir, flush_millis=summaries_flush_secs * 1000)\n",
    "  train_summary_writer.set_as_default()\n",
    "\n",
    "  eval_summary_writer = tf.compat.v2.summary.create_file_writer(\n",
    "      eval_dir, flush_millis=summaries_flush_secs * 1000)\n",
    "  eval_metrics = [\n",
    "      tf_metrics.AverageReturnMetric(buffer_size=num_eval_episodes),\n",
    "      tf_metrics.AverageEpisodeLengthMetric(buffer_size=num_eval_episodes)\n",
    "  ]\n",
    "\n",
    "  global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "  with tf.compat.v2.summary.record_if(\n",
    "      lambda: tf.math.equal(global_step % summary_interval, 0)):\n",
    "    if observations_allowlist is not None:\n",
    "      env_wrappers = [\n",
    "          functools.partial(\n",
    "              wrappers.FlattenObservationsWrapper,\n",
    "              observations_allowlist=[observations_allowlist])\n",
    "      ]\n",
    "    else:\n",
    "      env_wrappers = []\n",
    "\n",
    "    tf_env = tf_py_environment.TFPyEnvironment(py_env)\n",
    "    eval_tf_env = tf_py_environment.TFPyEnvironment(py_env)\n",
    "\n",
    "    actor_net = actor_rnn_network.ActorRnnNetwork(\n",
    "        tf_env.time_step_spec().observation,\n",
    "        tf_env.action_spec(),\n",
    "        input_fc_layer_params=actor_fc_layers,\n",
    "        lstm_size=actor_lstm_size,\n",
    "        output_fc_layer_params=actor_output_fc_layers)\n",
    "\n",
    "    critic_net_input_specs = (tf_env.time_step_spec().observation,\n",
    "                              tf_env.action_spec())\n",
    "\n",
    "    critic_net = critic_rnn_network.CriticRnnNetwork(\n",
    "        critic_net_input_specs,\n",
    "        observation_fc_layer_params=critic_obs_fc_layers,\n",
    "        action_fc_layer_params=critic_action_fc_layers,\n",
    "        joint_fc_layer_params=critic_joint_fc_layers,\n",
    "        lstm_size=critic_lstm_size,\n",
    "        output_fc_layer_params=critic_output_fc_layers,\n",
    "    )\n",
    "\n",
    "    tf_agent = ddpg_agent.DdpgAgent(\n",
    "        tf_env.time_step_spec(),\n",
    "        tf_env.action_spec(),\n",
    "        actor_network=actor_net,\n",
    "        critic_network=critic_net,\n",
    "        actor_optimizer=tf.compat.v1.train.AdamOptimizer(\n",
    "            learning_rate=actor_learning_rate),\n",
    "        critic_optimizer=tf.compat.v1.train.AdamOptimizer(\n",
    "            learning_rate=critic_learning_rate),\n",
    "        ou_stddev=ou_stddev,\n",
    "        ou_damping=ou_damping,\n",
    "        target_update_tau=target_update_tau,\n",
    "        target_update_period=target_update_period,\n",
    "        dqda_clipping=dqda_clipping,\n",
    "        td_errors_loss_fn=td_errors_loss_fn,\n",
    "        gamma=gamma,\n",
    "        reward_scale_factor=reward_scale_factor,\n",
    "        gradient_clipping=gradient_clipping,\n",
    "        debug_summaries=debug_summaries,\n",
    "        summarize_grads_and_vars=summarize_grads_and_vars,\n",
    "        train_step_counter=global_step)\n",
    "    tf_agent.initialize()\n",
    "\n",
    "    train_metrics = [\n",
    "        tf_metrics.NumberOfEpisodes(),\n",
    "        tf_metrics.EnvironmentSteps(),\n",
    "        tf_metrics.AverageReturnMetric(),\n",
    "        tf_metrics.AverageEpisodeLengthMetric(),\n",
    "    ]\n",
    "\n",
    "    eval_policy = tf_agent.policy\n",
    "    collect_policy = tf_agent.collect_policy\n",
    "    \n",
    "    saver = policy_saver.PolicySaver(eval_policy)\n",
    "\n",
    "    replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "        tf_agent.collect_data_spec,\n",
    "        batch_size=tf_env.batch_size,\n",
    "        max_length=replay_buffer_capacity)\n",
    "\n",
    "    initial_collect_driver = dynamic_episode_driver.DynamicEpisodeDriver(\n",
    "        tf_env,\n",
    "        collect_policy,\n",
    "        observers=[replay_buffer.add_batch] + train_metrics,\n",
    "        num_episodes=initial_collect_episodes)\n",
    "\n",
    "    collect_driver = dynamic_episode_driver.DynamicEpisodeDriver(\n",
    "        tf_env,\n",
    "        collect_policy,\n",
    "        observers=[replay_buffer.add_batch] + train_metrics,\n",
    "        num_episodes=collect_episodes_per_iteration)\n",
    "\n",
    "    if use_tf_functions:\n",
    "      initial_collect_driver.run = common.function(initial_collect_driver.run)\n",
    "      collect_driver.run = common.function(collect_driver.run)\n",
    "      tf_agent.train = common.function(tf_agent.train)\n",
    "\n",
    "    # Collect initial replay data.\n",
    "    logging.info(\n",
    "        'Initializing replay buffer by collecting experience for %d episodes '\n",
    "        'with a random policy.', initial_collect_episodes)\n",
    "    initial_collect_driver.run()\n",
    "\n",
    "    results = metric_utils.eager_compute(\n",
    "        eval_metrics,\n",
    "        eval_tf_env,\n",
    "        eval_policy,\n",
    "        num_episodes=num_eval_episodes,\n",
    "        train_step=global_step,\n",
    "        summary_writer=eval_summary_writer,\n",
    "        summary_prefix='Metrics',\n",
    "    )\n",
    "    if eval_metrics_callback is not None:\n",
    "      eval_metrics_callback(results, global_step.numpy())\n",
    "    metric_utils.log_metrics(eval_metrics)\n",
    "\n",
    "    time_step = None\n",
    "    policy_state = collect_policy.get_initial_state(tf_env.batch_size)\n",
    "\n",
    "    timed_at_step = global_step.numpy()\n",
    "    time_acc = 0\n",
    "\n",
    "    # Dataset generates trajectories with shape [BxTx...]\n",
    "    dataset = replay_buffer.as_dataset(\n",
    "        num_parallel_calls=3,\n",
    "        sample_batch_size=batch_size,\n",
    "        num_steps=train_sequence_length + 1).prefetch(3)\n",
    "    iterator = iter(dataset)\n",
    "\n",
    "    def train_step():\n",
    "      experience, _ = next(iterator)\n",
    "      return tf_agent.train(experience)\n",
    "\n",
    "    if use_tf_functions:\n",
    "      train_step = common.function(train_step)\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "      start_time = time.time()\n",
    "      time_step, policy_state = collect_driver.run(\n",
    "          time_step=time_step,\n",
    "          policy_state=policy_state,\n",
    "      )\n",
    "      for _ in range(train_steps_per_iteration):\n",
    "        train_loss = train_step()\n",
    "      time_acc += time.time() - start_time\n",
    "\n",
    "      if global_step.numpy() % log_interval == 0:\n",
    "        logging.info('step = %d, loss = %f', global_step.numpy(),\n",
    "                     train_loss.loss)\n",
    "        steps_per_sec = (global_step.numpy() - timed_at_step) / time_acc\n",
    "        logging.info('%.3f steps/sec', steps_per_sec)\n",
    "        tf.compat.v2.summary.scalar(\n",
    "            name='global_steps_per_sec', data=steps_per_sec, step=global_step)\n",
    "        timed_at_step = global_step.numpy()\n",
    "        time_acc = 0\n",
    "\n",
    "      for train_metric in train_metrics:\n",
    "        train_metric.tf_summaries(\n",
    "            train_step=global_step, step_metrics=train_metrics[:2])\n",
    "\n",
    "      if global_step.numpy() % eval_interval == 0:\n",
    "        results = metric_utils.eager_compute(\n",
    "            eval_metrics,\n",
    "            eval_tf_env,\n",
    "            eval_policy,\n",
    "            num_episodes=num_eval_episodes,\n",
    "            train_step=global_step,\n",
    "            summary_writer=eval_summary_writer,\n",
    "            summary_prefix='Metrics',\n",
    "        )\n",
    "        if eval_metrics_callback is not None:\n",
    "          eval_metrics_callback(results, global_step.numpy())\n",
    "        metric_utils.log_metrics(eval_metrics)\n",
    "        avg_return, cullsteps = compute_avg_return(eval_tf_env, eval_policy, num_episodes=100, verbose=False)\n",
    "        print('step {0}: average return = {1:.1f} cullsteps = {2:.1f}'.format(global_step.numpy(), \n",
    "                                                                            avg_return.numpy().item(), cullsteps))\n",
    "        if avg_return > best_return:\n",
    "            if avg_return > -5000:\n",
    "                best_return = avg_return\n",
    "                print('Final best return: ', best_return)\n",
    "                saver.save(os.path.join(policy_dir, str(global_step.numpy())))\n",
    "                break\n",
    "            else:\n",
    "                best_return = avg_return\n",
    "                print('New best return: ', best_return)\n",
    "                saver.save(os.path.join(policy_dir, str(global_step.numpy())))\n",
    "\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c098712-8656-4607-9014-a1a1d4710bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.9/site-packages/tensorflow/python/data/experimental/ops/counter.py:66: scan (from tensorflow.python.data.experimental.ops.scan_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.scan(...) instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.9/site-packages/tensorflow/python/data/experimental/ops/counter.py:66: scan (from tensorflow.python.data.experimental.ops.scan_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.scan(...) instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:382: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:382: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1000: average return = -53007.3 cullsteps = 0.0\n",
      "step 2000: average return = -69961.6 cullsteps = 0.0\n",
      "step 3000: average return = -62307.3 cullsteps = 0.0\n",
      "step 4000: average return = -63926.4 cullsteps = 0.0\n",
      "step 5000: average return = -58637.0 cullsteps = 0.0\n",
      "step 6000: average return = -74090.5 cullsteps = 0.0\n",
      "step 7000: average return = -26445.3 cullsteps = 75.3\n",
      "step 8000: average return = -64737.2 cullsteps = 8.5\n",
      "step 9000: average return = -59287.6 cullsteps = 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10000: average return = -15017.5 cullsteps = 74.8\n",
      "New best return:  tf.Tensor([-15017.549], shape=(1,), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/10000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/10000/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 11000: average return = -19745.5 cullsteps = 87.5\n",
      "step 12000: average return = -51027.2 cullsteps = 25.5\n",
      "step 13000: average return = -49020.0 cullsteps = 8.2\n",
      "step 14000: average return = -40321.9 cullsteps = 6.5\n",
      "step 15000: average return = -18364.5 cullsteps = 87.8\n",
      "step 16000: average return = -44134.6 cullsteps = 11.0\n",
      "step 17000: average return = -68219.5 cullsteps = 4.4\n",
      "step 18000: average return = -58522.2 cullsteps = 4.0\n",
      "step 19000: average return = -53808.4 cullsteps = 3.6\n",
      "step 20000: average return = -64987.3 cullsteps = 6.1\n",
      "step 21000: average return = -48048.3 cullsteps = 18.4\n",
      "step 22000: average return = -39889.0 cullsteps = 45.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 23000: average return = -10464.1 cullsteps = 21.6\n",
      "New best return:  tf.Tensor([-10464.146], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/23000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/23000/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 24000: average return = -13331.8 cullsteps = 28.6\n",
      "step 25000: average return = -29932.5 cullsteps = 42.7\n",
      "step 26000: average return = -10475.1 cullsteps = 39.4\n",
      "step 27000: average return = -10533.1 cullsteps = 40.3\n",
      "step 28000: average return = -68697.6 cullsteps = 1.6\n",
      "step 29000: average return = -51427.2 cullsteps = 6.8\n",
      "step 30000: average return = -37188.8 cullsteps = 24.4\n",
      "step 31000: average return = -20565.5 cullsteps = 30.9\n",
      "step 32000: average return = -37246.4 cullsteps = 13.7\n",
      "step 33000: average return = -12033.7 cullsteps = 48.2\n",
      "step 34000: average return = -13417.1 cullsteps = 43.2\n",
      "step 35000: average return = -13984.4 cullsteps = 45.5\n",
      "step 36000: average return = -13970.4 cullsteps = 56.9\n",
      "step 37000: average return = -29402.6 cullsteps = 26.0\n",
      "step 38000: average return = -34104.7 cullsteps = 17.0\n",
      "step 39000: average return = -18723.8 cullsteps = 25.4\n",
      "step 40000: average return = -13199.3 cullsteps = 52.5\n",
      "step 41000: average return = -17508.3 cullsteps = 26.8\n",
      "step 42000: average return = -11569.9 cullsteps = 34.4\n",
      "step 43000: average return = -11568.4 cullsteps = 37.5\n",
      "step 44000: average return = -13022.5 cullsteps = 31.2\n",
      "step 45000: average return = -45965.8 cullsteps = 10.0\n",
      "step 46000: average return = -29278.5 cullsteps = 15.5\n",
      "step 47000: average return = -22450.2 cullsteps = 14.0\n",
      "step 48000: average return = -10543.1 cullsteps = 24.0\n",
      "step 49000: average return = -11222.9 cullsteps = 22.8\n",
      "step 50000: average return = -21363.2 cullsteps = 19.6\n",
      "step 51000: average return = -17566.3 cullsteps = 24.3\n",
      "step 52000: average return = -12329.3 cullsteps = 27.0\n",
      "step 53000: average return = -11233.7 cullsteps = 32.9\n",
      "step 54000: average return = -12267.1 cullsteps = 26.8\n",
      "step 55000: average return = -11348.8 cullsteps = 21.0\n",
      "step 56000: average return = -13504.2 cullsteps = 26.9\n",
      "step 57000: average return = -10924.2 cullsteps = 31.8\n",
      "step 58000: average return = -15128.5 cullsteps = 37.0\n",
      "step 59000: average return = -12235.6 cullsteps = 30.7\n",
      "step 60000: average return = -11248.4 cullsteps = 21.4\n",
      "step 61000: average return = -10957.0 cullsteps = 26.8\n",
      "step 62000: average return = -17759.2 cullsteps = 26.2\n",
      "step 63000: average return = -13663.0 cullsteps = 24.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 64000: average return = -9625.2 cullsteps = 20.9\n",
      "New best return:  tf.Tensor([-9625.163], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/64000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/64000/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 65000: average return = -9661.1 cullsteps = 15.2\n",
      "step 66000: average return = -10876.6 cullsteps = 17.4\n",
      "step 67000: average return = -15714.5 cullsteps = 31.1\n",
      "step 68000: average return = -11580.4 cullsteps = 36.2\n",
      "step 69000: average return = -13135.0 cullsteps = 29.5\n",
      "step 70000: average return = -20836.8 cullsteps = 22.2\n",
      "step 71000: average return = -17295.8 cullsteps = 24.0\n",
      "step 72000: average return = -11268.6 cullsteps = 32.2\n",
      "step 73000: average return = -13498.8 cullsteps = 38.9\n",
      "step 74000: average return = -13688.2 cullsteps = 35.4\n",
      "step 75000: average return = -14581.2 cullsteps = 47.1\n",
      "step 76000: average return = -12693.2 cullsteps = 55.4\n",
      "step 77000: average return = -12228.1 cullsteps = 56.3\n",
      "step 78000: average return = -11267.7 cullsteps = 35.9\n",
      "step 79000: average return = -12951.5 cullsteps = 39.5\n",
      "step 80000: average return = -15105.1 cullsteps = 24.2\n",
      "step 81000: average return = -22179.8 cullsteps = 26.3\n",
      "step 82000: average return = -22904.8 cullsteps = 24.1\n",
      "step 83000: average return = -9727.9 cullsteps = 34.0\n",
      "step 84000: average return = -10234.6 cullsteps = 37.5\n",
      "step 85000: average return = -9715.2 cullsteps = 32.9\n",
      "step 86000: average return = -10498.9 cullsteps = 26.7\n",
      "step 87000: average return = -17301.0 cullsteps = 18.2\n",
      "step 88000: average return = -19301.3 cullsteps = 18.0\n",
      "step 89000: average return = -40834.9 cullsteps = 5.5\n",
      "step 90000: average return = -13994.8 cullsteps = 15.8\n",
      "step 91000: average return = -12327.5 cullsteps = 20.6\n",
      "step 92000: average return = -11013.5 cullsteps = 18.7\n",
      "step 93000: average return = -11996.9 cullsteps = 25.9\n",
      "step 94000: average return = -11432.4 cullsteps = 18.7\n",
      "step 95000: average return = -11323.7 cullsteps = 30.3\n",
      "step 96000: average return = -14612.8 cullsteps = 64.2\n",
      "step 97000: average return = -27822.9 cullsteps = 21.1\n",
      "step 98000: average return = -42704.6 cullsteps = 15.7\n",
      "step 99000: average return = -20811.3 cullsteps = 34.9\n",
      "step 100000: average return = -11997.7 cullsteps = 53.5\n",
      "step 101000: average return = -14060.2 cullsteps = 65.2\n",
      "step 102000: average return = -11001.5 cullsteps = 44.6\n",
      "step 103000: average return = -10126.7 cullsteps = 32.4\n",
      "step 104000: average return = -11025.0 cullsteps = 31.5\n",
      "step 105000: average return = -14213.3 cullsteps = 17.9\n",
      "step 106000: average return = -16126.4 cullsteps = 20.0\n",
      "step 107000: average return = -16824.7 cullsteps = 23.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 108000: average return = -9443.7 cullsteps = 31.9\n",
      "New best return:  tf.Tensor([-9443.699], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/108000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/108000/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 109000: average return = -11366.1 cullsteps = 23.2\n",
      "step 110000: average return = -25262.5 cullsteps = 29.5\n",
      "step 111000: average return = -20359.4 cullsteps = 14.9\n",
      "step 112000: average return = -29995.3 cullsteps = 7.4\n",
      "step 113000: average return = -24136.1 cullsteps = 12.4\n",
      "step 114000: average return = -12693.8 cullsteps = 16.5\n",
      "step 115000: average return = -9640.9 cullsteps = 33.0\n",
      "step 116000: average return = -21790.8 cullsteps = 15.5\n",
      "step 117000: average return = -17084.0 cullsteps = 17.6\n",
      "step 118000: average return = -10934.7 cullsteps = 35.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `function_with_signature` contains input name(s) 0/step_type, 0/reward, 0/discount, 0/observation, 1/0, 1/1 with unsupported characters which will be renamed to step_type, reward, discount, observation, unknown, unknown_0 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ActorRnnNetwork_layer_call_and_return_conditional_losses, ActorRnnNetwork_layer_call_fn, dynamic_unroll_layer_call_and_return_conditional_losses, dynamic_unroll_layer_call_fn, ActorRnnNetwork_layer_call_fn while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 119000: average return = -8041.8 cullsteps = 27.1\n",
      "New best return:  tf.Tensor([-8041.8413], shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/119000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:558: UserWarning: Encoding a StructuredValue with type tfp.distributions.Deterministic_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.\n",
      "  warnings.warn(\"Encoding a StructuredValue with type %s; loading this \"\n",
      "INFO:tensorflow:Assets written to: /home/jovyan/Masterarbeit/RNN_DDPG/policy/119000/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 120000: average return = -9356.0 cullsteps = 37.0\n",
      "step 121000: average return = -11223.4 cullsteps = 49.4\n",
      "step 122000: average return = -12366.4 cullsteps = 60.7\n",
      "step 123000: average return = -11667.8 cullsteps = 53.6\n",
      "step 124000: average return = -15492.7 cullsteps = 45.6\n",
      "step 125000: average return = -11139.2 cullsteps = 41.8\n",
      "step 126000: average return = -11230.9 cullsteps = 39.6\n",
      "step 127000: average return = -12571.6 cullsteps = 37.3\n",
      "step 128000: average return = -10303.7 cullsteps = 28.8\n",
      "step 129000: average return = -13373.6 cullsteps = 23.3\n",
      "step 130000: average return = -34919.8 cullsteps = 17.8\n",
      "step 131000: average return = -16586.3 cullsteps = 19.9\n",
      "step 132000: average return = -11794.0 cullsteps = 45.8\n",
      "step 133000: average return = -10488.4 cullsteps = 40.4\n",
      "step 134000: average return = -11265.4 cullsteps = 43.7\n",
      "step 135000: average return = -12390.8 cullsteps = 27.2\n",
      "step 136000: average return = -34234.1 cullsteps = 12.3\n",
      "step 137000: average return = -12890.5 cullsteps = 31.0\n",
      "step 138000: average return = -12077.5 cullsteps = 21.7\n",
      "step 139000: average return = -25884.9 cullsteps = 11.1\n",
      "step 140000: average return = -18172.6 cullsteps = 18.4\n",
      "step 141000: average return = -20031.0 cullsteps = 23.7\n",
      "step 142000: average return = -15144.7 cullsteps = 32.9\n",
      "step 143000: average return = -33483.3 cullsteps = 13.2\n",
      "step 144000: average return = -11837.7 cullsteps = 21.1\n",
      "step 145000: average return = -10863.7 cullsteps = 23.0\n",
      "step 146000: average return = -11077.9 cullsteps = 29.1\n",
      "step 147000: average return = -12379.6 cullsteps = 49.7\n",
      "step 148000: average return = -9490.1 cullsteps = 38.5\n",
      "step 149000: average return = -11617.0 cullsteps = 41.7\n",
      "step 150000: average return = -18670.7 cullsteps = 37.8\n",
      "step 151000: average return = -14567.6 cullsteps = 56.4\n",
      "step 152000: average return = -12464.9 cullsteps = 51.4\n",
      "step 153000: average return = -10763.1 cullsteps = 39.5\n",
      "step 154000: average return = -11364.2 cullsteps = 34.3\n",
      "step 155000: average return = -12505.8 cullsteps = 40.7\n",
      "step 156000: average return = -12701.3 cullsteps = 55.2\n",
      "step 157000: average return = -9756.3 cullsteps = 34.0\n",
      "step 158000: average return = -12306.4 cullsteps = 47.0\n",
      "step 159000: average return = -11098.4 cullsteps = 37.2\n",
      "step 160000: average return = -10744.4 cullsteps = 41.8\n",
      "step 161000: average return = -10532.0 cullsteps = 46.7\n",
      "step 162000: average return = -14476.2 cullsteps = 67.8\n",
      "step 163000: average return = -12460.8 cullsteps = 42.4\n",
      "step 164000: average return = -14320.2 cullsteps = 61.0\n",
      "step 165000: average return = -11090.8 cullsteps = 40.5\n",
      "step 166000: average return = -9310.6 cullsteps = 34.0\n",
      "step 167000: average return = -10713.4 cullsteps = 35.3\n",
      "step 168000: average return = -10923.8 cullsteps = 37.3\n",
      "step 169000: average return = -10499.0 cullsteps = 37.7\n",
      "step 170000: average return = -11841.9 cullsteps = 27.2\n",
      "step 171000: average return = -11898.9 cullsteps = 40.7\n",
      "step 172000: average return = -10999.5 cullsteps = 35.7\n",
      "step 173000: average return = -12941.8 cullsteps = 54.4\n",
      "step 174000: average return = -11859.5 cullsteps = 56.4\n",
      "step 175000: average return = -11047.8 cullsteps = 50.7\n",
      "step 176000: average return = -10723.6 cullsteps = 47.2\n",
      "step 177000: average return = -10405.4 cullsteps = 42.3\n",
      "step 178000: average return = -11674.8 cullsteps = 45.9\n",
      "step 179000: average return = -12432.7 cullsteps = 45.4\n",
      "step 180000: average return = -12803.3 cullsteps = 54.7\n",
      "step 181000: average return = -12150.9 cullsteps = 35.9\n",
      "step 182000: average return = -9830.8 cullsteps = 27.5\n",
      "step 183000: average return = -10640.6 cullsteps = 28.2\n",
      "step 184000: average return = -14459.6 cullsteps = 36.5\n",
      "step 185000: average return = -12186.7 cullsteps = 36.6\n",
      "step 186000: average return = -10371.1 cullsteps = 31.6\n",
      "step 187000: average return = -10463.1 cullsteps = 32.4\n",
      "step 188000: average return = -11505.1 cullsteps = 43.9\n",
      "step 189000: average return = -11624.7 cullsteps = 27.2\n",
      "step 190000: average return = -10998.9 cullsteps = 24.6\n",
      "step 191000: average return = -11105.4 cullsteps = 24.9\n",
      "step 192000: average return = -10249.3 cullsteps = 22.8\n",
      "step 193000: average return = -9560.6 cullsteps = 23.8\n",
      "step 194000: average return = -14855.8 cullsteps = 27.2\n",
      "step 195000: average return = -12583.3 cullsteps = 31.5\n",
      "step 196000: average return = -12348.1 cullsteps = 36.3\n",
      "step 197000: average return = -11320.4 cullsteps = 39.6\n",
      "step 198000: average return = -12432.9 cullsteps = 48.0\n",
      "step 199000: average return = -13404.1 cullsteps = 31.4\n",
      "step 200000: average return = -8987.4 cullsteps = 31.0\n",
      "step 201000: average return = -10135.3 cullsteps = 38.6\n",
      "step 202000: average return = -12629.5 cullsteps = 36.9\n",
      "step 203000: average return = -11313.4 cullsteps = 29.2\n",
      "step 204000: average return = -10563.3 cullsteps = 24.7\n",
      "step 205000: average return = -11540.3 cullsteps = 25.3\n",
      "step 206000: average return = -10475.2 cullsteps = 29.1\n",
      "step 207000: average return = -11561.5 cullsteps = 39.4\n",
      "step 208000: average return = -12924.5 cullsteps = 27.9\n",
      "step 209000: average return = -13234.7 cullsteps = 18.5\n",
      "step 210000: average return = -12340.8 cullsteps = 32.1\n",
      "step 211000: average return = -9996.5 cullsteps = 30.4\n",
      "step 212000: average return = -11630.0 cullsteps = 41.4\n",
      "step 213000: average return = -13241.5 cullsteps = 50.1\n",
      "step 214000: average return = -14271.8 cullsteps = 55.8\n",
      "step 215000: average return = -11169.2 cullsteps = 46.6\n",
      "step 216000: average return = -11712.6 cullsteps = 50.3\n",
      "step 217000: average return = -13106.0 cullsteps = 47.8\n",
      "step 218000: average return = -13690.4 cullsteps = 38.4\n",
      "step 219000: average return = -12498.1 cullsteps = 34.1\n",
      "step 220000: average return = -21689.0 cullsteps = 99.5\n",
      "step 221000: average return = -16281.5 cullsteps = 89.2\n",
      "step 222000: average return = -12186.0 cullsteps = 61.7\n",
      "step 223000: average return = -12845.0 cullsteps = 45.5\n",
      "step 224000: average return = -11680.7 cullsteps = 35.2\n",
      "step 225000: average return = -15169.0 cullsteps = 45.9\n",
      "step 226000: average return = -16641.0 cullsteps = 67.4\n",
      "step 227000: average return = -17937.0 cullsteps = 41.2\n",
      "step 228000: average return = -10033.3 cullsteps = 29.5\n",
      "step 229000: average return = -18107.4 cullsteps = 18.0\n",
      "step 230000: average return = -20099.3 cullsteps = 72.7\n",
      "step 231000: average return = -17658.8 cullsteps = 77.3\n",
      "step 232000: average return = -14573.1 cullsteps = 63.7\n",
      "step 233000: average return = -16643.5 cullsteps = 25.6\n",
      "step 234000: average return = -15571.1 cullsteps = 32.7\n",
      "step 235000: average return = -13783.6 cullsteps = 56.4\n",
      "step 236000: average return = -14205.0 cullsteps = 53.3\n",
      "step 237000: average return = -14097.7 cullsteps = 46.1\n",
      "step 238000: average return = -12059.4 cullsteps = 37.3\n",
      "step 239000: average return = -25401.7 cullsteps = 80.5\n",
      "step 240000: average return = -12326.9 cullsteps = 37.5\n",
      "step 241000: average return = -13673.6 cullsteps = 52.2\n",
      "step 242000: average return = -11129.6 cullsteps = 43.0\n",
      "step 243000: average return = -10585.5 cullsteps = 37.7\n",
      "step 244000: average return = -14654.1 cullsteps = 55.4\n",
      "step 245000: average return = -18300.7 cullsteps = 59.9\n",
      "step 246000: average return = -15021.0 cullsteps = 57.2\n",
      "step 247000: average return = -19522.0 cullsteps = 69.3\n",
      "step 248000: average return = -19621.7 cullsteps = 92.3\n",
      "step 249000: average return = -16159.3 cullsteps = 77.3\n",
      "step 250000: average return = -18798.0 cullsteps = 92.4\n",
      "step 251000: average return = -19797.0 cullsteps = 95.4\n",
      "step 252000: average return = -13584.9 cullsteps = 58.3\n",
      "step 253000: average return = -12500.2 cullsteps = 46.0\n",
      "step 254000: average return = -14082.2 cullsteps = 49.0\n",
      "step 255000: average return = -13592.0 cullsteps = 54.3\n",
      "step 256000: average return = -12750.5 cullsteps = 52.0\n",
      "step 257000: average return = -11300.5 cullsteps = 54.2\n",
      "step 258000: average return = -12262.2 cullsteps = 42.1\n",
      "step 259000: average return = -17403.6 cullsteps = 68.4\n",
      "step 260000: average return = -14319.1 cullsteps = 63.1\n",
      "step 261000: average return = -12231.7 cullsteps = 34.5\n",
      "step 262000: average return = -20658.5 cullsteps = 19.4\n",
      "step 263000: average return = -14711.4 cullsteps = 22.2\n",
      "step 264000: average return = -13353.7 cullsteps = 36.1\n",
      "step 265000: average return = -11945.5 cullsteps = 36.9\n",
      "step 266000: average return = -16804.0 cullsteps = 60.0\n",
      "step 267000: average return = -15147.0 cullsteps = 57.2\n",
      "step 268000: average return = -18302.5 cullsteps = 52.4\n",
      "step 269000: average return = -21466.8 cullsteps = 49.6\n",
      "step 270000: average return = -19309.7 cullsteps = 68.1\n",
      "step 271000: average return = -15465.1 cullsteps = 56.4\n",
      "step 272000: average return = -14017.5 cullsteps = 40.9\n",
      "step 273000: average return = -45577.1 cullsteps = 23.5\n",
      "step 274000: average return = -44024.9 cullsteps = 16.1\n",
      "step 275000: average return = -64141.1 cullsteps = 0.3\n",
      "step 276000: average return = -38841.2 cullsteps = 14.7\n",
      "step 277000: average return = -56108.4 cullsteps = 1.7\n",
      "step 278000: average return = -55949.9 cullsteps = 6.8\n",
      "step 279000: average return = -20662.9 cullsteps = 72.7\n",
      "step 280000: average return = -20538.0 cullsteps = 62.5\n",
      "step 281000: average return = -17689.2 cullsteps = 49.6\n",
      "step 282000: average return = -19419.5 cullsteps = 59.3\n",
      "step 283000: average return = -19809.8 cullsteps = 58.0\n",
      "step 284000: average return = -20676.0 cullsteps = 80.3\n",
      "step 285000: average return = -18506.1 cullsteps = 35.4\n",
      "step 286000: average return = -19425.0 cullsteps = 40.0\n",
      "step 287000: average return = -32123.1 cullsteps = 21.3\n",
      "step 288000: average return = -17295.0 cullsteps = 54.7\n",
      "step 289000: average return = -29061.0 cullsteps = 38.2\n",
      "step 290000: average return = -21254.9 cullsteps = 49.1\n",
      "step 291000: average return = -20180.0 cullsteps = 80.9\n",
      "step 292000: average return = -16451.0 cullsteps = 66.8\n",
      "step 293000: average return = -18040.4 cullsteps = 72.5\n",
      "step 294000: average return = -15492.0 cullsteps = 60.2\n",
      "step 295000: average return = -15126.0 cullsteps = 54.8\n",
      "step 296000: average return = -16795.7 cullsteps = 63.8\n",
      "step 297000: average return = -14235.2 cullsteps = 59.0\n",
      "step 298000: average return = -12600.9 cullsteps = 49.1\n",
      "step 299000: average return = -13889.4 cullsteps = 59.5\n",
      "step 300000: average return = -11739.4 cullsteps = 51.0\n",
      "step 301000: average return = -20258.6 cullsteps = 44.4\n",
      "step 302000: average return = -17231.9 cullsteps = 65.8\n",
      "step 303000: average return = -12971.5 cullsteps = 55.3\n",
      "step 304000: average return = -13428.2 cullsteps = 61.8\n",
      "step 305000: average return = -26280.5 cullsteps = 36.6\n",
      "step 306000: average return = -13771.0 cullsteps = 60.3\n",
      "step 307000: average return = -13892.8 cullsteps = 60.1\n",
      "step 308000: average return = -14030.9 cullsteps = 64.8\n",
      "step 309000: average return = -13794.2 cullsteps = 49.4\n",
      "step 310000: average return = -13282.2 cullsteps = 51.0\n",
      "step 311000: average return = -12426.6 cullsteps = 47.5\n",
      "step 312000: average return = -12462.5 cullsteps = 50.8\n",
      "step 313000: average return = -14224.8 cullsteps = 33.6\n",
      "step 314000: average return = -32457.7 cullsteps = 13.0\n",
      "step 315000: average return = -52150.9 cullsteps = 4.0\n",
      "step 316000: average return = -45267.8 cullsteps = 8.0\n",
      "step 317000: average return = -13386.2 cullsteps = 34.9\n",
      "step 318000: average return = -12188.6 cullsteps = 45.6\n",
      "step 319000: average return = -13427.2 cullsteps = 53.1\n",
      "step 320000: average return = -11600.2 cullsteps = 44.5\n",
      "step 321000: average return = -16516.5 cullsteps = 28.5\n",
      "step 322000: average return = -14632.9 cullsteps = 25.2\n",
      "step 323000: average return = -15510.4 cullsteps = 23.2\n",
      "step 324000: average return = -11293.2 cullsteps = 31.0\n",
      "step 325000: average return = -12162.7 cullsteps = 41.1\n",
      "step 326000: average return = -13452.0 cullsteps = 55.9\n",
      "step 327000: average return = -12369.0 cullsteps = 42.0\n",
      "step 328000: average return = -13181.3 cullsteps = 40.8\n",
      "step 329000: average return = -15362.5 cullsteps = 53.7\n",
      "step 330000: average return = -13461.2 cullsteps = 43.4\n",
      "step 331000: average return = -13236.1 cullsteps = 47.8\n",
      "step 332000: average return = -14087.7 cullsteps = 65.3\n",
      "step 333000: average return = -12680.1 cullsteps = 48.8\n",
      "step 334000: average return = -17001.7 cullsteps = 44.1\n",
      "step 335000: average return = -25120.8 cullsteps = 23.6\n",
      "step 336000: average return = -27039.6 cullsteps = 18.6\n",
      "step 337000: average return = -22009.3 cullsteps = 18.2\n",
      "step 338000: average return = -12691.9 cullsteps = 21.4\n",
      "step 339000: average return = -14673.7 cullsteps = 21.9\n",
      "step 340000: average return = -14971.7 cullsteps = 34.6\n",
      "step 341000: average return = -11915.8 cullsteps = 38.3\n",
      "step 342000: average return = -13856.9 cullsteps = 47.4\n",
      "step 343000: average return = -13673.0 cullsteps = 59.3\n",
      "step 344000: average return = -12444.9 cullsteps = 45.8\n",
      "step 345000: average return = -13799.2 cullsteps = 50.9\n",
      "step 346000: average return = -22766.9 cullsteps = 48.3\n",
      "step 347000: average return = -12977.3 cullsteps = 53.9\n",
      "step 348000: average return = -11390.1 cullsteps = 50.0\n",
      "step 349000: average return = -13678.2 cullsteps = 68.1\n",
      "step 350000: average return = -10259.7 cullsteps = 53.8\n",
      "step 351000: average return = -13458.1 cullsteps = 67.7\n",
      "step 352000: average return = -14222.8 cullsteps = 72.8\n",
      "step 353000: average return = -15601.9 cullsteps = 73.6\n",
      "step 354000: average return = -15343.9 cullsteps = 75.5\n",
      "step 355000: average return = -14235.4 cullsteps = 65.1\n",
      "step 356000: average return = -15123.2 cullsteps = 66.2\n",
      "step 357000: average return = -15191.2 cullsteps = 55.8\n",
      "step 358000: average return = -14789.0 cullsteps = 54.7\n",
      "step 359000: average return = -19588.6 cullsteps = 87.1\n",
      "step 360000: average return = -21234.8 cullsteps = 97.5\n",
      "step 361000: average return = -12917.1 cullsteps = 55.2\n",
      "step 362000: average return = -14460.5 cullsteps = 58.8\n",
      "step 363000: average return = -13328.5 cullsteps = 52.1\n",
      "step 364000: average return = -14261.2 cullsteps = 49.1\n",
      "step 365000: average return = -15046.0 cullsteps = 60.4\n",
      "step 366000: average return = -12890.1 cullsteps = 52.1\n",
      "step 367000: average return = -16449.9 cullsteps = 39.7\n",
      "step 368000: average return = -15809.4 cullsteps = 56.2\n",
      "step 369000: average return = -25848.2 cullsteps = 78.3\n",
      "step 370000: average return = -20561.3 cullsteps = 67.8\n",
      "step 371000: average return = -23784.5 cullsteps = 43.7\n",
      "step 372000: average return = -24426.7 cullsteps = 72.7\n",
      "step 373000: average return = -21127.9 cullsteps = 35.1\n",
      "step 374000: average return = -26169.8 cullsteps = 19.3\n",
      "step 375000: average return = -44098.4 cullsteps = 9.9\n",
      "step 376000: average return = -38349.3 cullsteps = 8.1\n",
      "step 377000: average return = -25012.6 cullsteps = 22.1\n",
      "step 378000: average return = -32953.3 cullsteps = 8.1\n",
      "step 379000: average return = -37918.8 cullsteps = 6.7\n",
      "step 380000: average return = -10393.8 cullsteps = 38.5\n",
      "step 381000: average return = -15261.9 cullsteps = 56.5\n",
      "step 382000: average return = -12739.5 cullsteps = 41.2\n",
      "step 383000: average return = -13157.1 cullsteps = 46.6\n",
      "step 384000: average return = -12073.8 cullsteps = 42.3\n",
      "step 385000: average return = -15970.6 cullsteps = 27.7\n",
      "step 386000: average return = -23141.2 cullsteps = 25.8\n",
      "step 387000: average return = -13425.7 cullsteps = 44.4\n",
      "step 388000: average return = -14887.3 cullsteps = 55.0\n",
      "step 389000: average return = -13299.9 cullsteps = 65.4\n",
      "step 390000: average return = -16077.1 cullsteps = 38.2\n",
      "step 391000: average return = -17103.3 cullsteps = 37.4\n",
      "step 392000: average return = -13158.1 cullsteps = 52.1\n",
      "step 393000: average return = -14163.6 cullsteps = 44.5\n",
      "step 394000: average return = -15566.9 cullsteps = 41.5\n",
      "step 395000: average return = -12884.5 cullsteps = 51.3\n",
      "step 396000: average return = -17328.2 cullsteps = 35.1\n",
      "step 397000: average return = -17807.9 cullsteps = 41.8\n",
      "step 398000: average return = -15453.3 cullsteps = 64.1\n",
      "step 399000: average return = -14243.2 cullsteps = 44.9\n",
      "step 400000: average return = -16945.8 cullsteps = 59.7\n",
      "step 401000: average return = -19701.5 cullsteps = 56.4\n",
      "step 402000: average return = -17944.2 cullsteps = 76.2\n",
      "step 403000: average return = -12944.9 cullsteps = 52.5\n",
      "step 404000: average return = -17167.4 cullsteps = 45.3\n",
      "step 405000: average return = -14350.4 cullsteps = 55.5\n",
      "step 406000: average return = -18651.3 cullsteps = 73.4\n",
      "step 407000: average return = -14135.8 cullsteps = 55.2\n",
      "step 408000: average return = -18546.9 cullsteps = 75.5\n",
      "step 409000: average return = -19659.3 cullsteps = 88.5\n",
      "step 410000: average return = -20595.6 cullsteps = 38.5\n",
      "step 411000: average return = -24779.0 cullsteps = 33.7\n",
      "step 412000: average return = -28356.6 cullsteps = 43.4\n",
      "step 413000: average return = -30019.5 cullsteps = 22.3\n",
      "step 414000: average return = -19328.2 cullsteps = 26.0\n",
      "step 415000: average return = -17298.2 cullsteps = 54.5\n",
      "step 416000: average return = -18647.5 cullsteps = 58.6\n",
      "step 417000: average return = -19969.7 cullsteps = 36.3\n",
      "step 418000: average return = -25234.6 cullsteps = 29.3\n",
      "step 419000: average return = -22780.8 cullsteps = 54.0\n",
      "step 420000: average return = -26700.9 cullsteps = 38.3\n",
      "step 421000: average return = -29157.6 cullsteps = 48.9\n",
      "step 422000: average return = -18951.8 cullsteps = 62.5\n",
      "step 423000: average return = -18161.1 cullsteps = 80.4\n",
      "step 424000: average return = -14829.4 cullsteps = 70.0\n",
      "step 425000: average return = -17586.4 cullsteps = 68.6\n",
      "step 426000: average return = -16823.7 cullsteps = 54.0\n",
      "step 427000: average return = -14542.5 cullsteps = 56.2\n",
      "step 428000: average return = -15911.6 cullsteps = 49.3\n",
      "step 429000: average return = -17873.8 cullsteps = 78.0\n",
      "step 430000: average return = -25187.0 cullsteps = 85.0\n",
      "step 431000: average return = -24796.7 cullsteps = 88.8\n",
      "step 432000: average return = -34642.2 cullsteps = 107.8\n",
      "step 433000: average return = -19886.7 cullsteps = 88.5\n",
      "step 434000: average return = -17847.8 cullsteps = 69.8\n",
      "step 435000: average return = -17667.6 cullsteps = 70.7\n",
      "step 436000: average return = -20183.8 cullsteps = 73.9\n",
      "step 437000: average return = -16552.9 cullsteps = 72.8\n",
      "step 438000: average return = -18236.6 cullsteps = 77.4\n",
      "step 439000: average return = -15172.8 cullsteps = 65.4\n",
      "step 440000: average return = -20472.6 cullsteps = 83.7\n",
      "step 441000: average return = -18499.6 cullsteps = 71.9\n",
      "step 442000: average return = -18072.7 cullsteps = 70.9\n",
      "step 443000: average return = -18654.7 cullsteps = 85.0\n",
      "step 444000: average return = -15057.0 cullsteps = 65.0\n",
      "step 445000: average return = -15038.6 cullsteps = 78.9\n",
      "step 446000: average return = -19420.4 cullsteps = 93.4\n",
      "step 447000: average return = -32181.1 cullsteps = 105.6\n",
      "step 448000: average return = -21413.9 cullsteps = 97.3\n",
      "step 449000: average return = -17013.6 cullsteps = 79.4\n",
      "step 450000: average return = -17941.9 cullsteps = 85.2\n",
      "step 451000: average return = -16520.1 cullsteps = 83.7\n",
      "step 452000: average return = -16170.6 cullsteps = 69.1\n",
      "step 453000: average return = -17332.2 cullsteps = 78.4\n",
      "step 454000: average return = -17269.2 cullsteps = 65.4\n",
      "step 455000: average return = -16601.8 cullsteps = 48.6\n",
      "step 456000: average return = -18332.5 cullsteps = 64.5\n",
      "step 457000: average return = -23525.6 cullsteps = 93.3\n",
      "step 458000: average return = -26484.6 cullsteps = 62.6\n",
      "step 459000: average return = -22069.8 cullsteps = 94.8\n",
      "step 460000: average return = -50800.4 cullsteps = 11.2\n",
      "step 461000: average return = -21722.2 cullsteps = 91.3\n",
      "step 462000: average return = -20698.0 cullsteps = 80.2\n",
      "step 463000: average return = -18382.2 cullsteps = 78.8\n",
      "step 465000: average return = -16130.0 cullsteps = 74.4\n",
      "step 466000: average return = -18537.5 cullsteps = 82.9\n",
      "step 467000: average return = -12901.9 cullsteps = 54.3\n",
      "step 468000: average return = -16088.9 cullsteps = 51.3\n",
      "step 469000: average return = -12809.2 cullsteps = 56.0\n",
      "step 470000: average return = -15153.0 cullsteps = 66.1\n",
      "step 471000: average return = -18229.3 cullsteps = 69.4\n",
      "step 472000: average return = -16768.6 cullsteps = 64.5\n",
      "step 473000: average return = -20516.6 cullsteps = 60.8\n",
      "step 474000: average return = -18795.9 cullsteps = 44.2\n",
      "step 475000: average return = -16855.8 cullsteps = 56.6\n",
      "step 476000: average return = -15332.7 cullsteps = 48.5\n",
      "step 477000: average return = -12882.8 cullsteps = 44.9\n",
      "step 478000: average return = -12372.3 cullsteps = 36.2\n",
      "step 479000: average return = -12085.5 cullsteps = 41.2\n",
      "step 480000: average return = -11525.5 cullsteps = 44.6\n",
      "step 481000: average return = -15305.9 cullsteps = 71.5\n",
      "step 482000: average return = -18500.8 cullsteps = 73.4\n",
      "step 483000: average return = -11595.9 cullsteps = 45.9\n",
      "step 484000: average return = -17052.4 cullsteps = 29.1\n",
      "step 485000: average return = -14112.1 cullsteps = 37.6\n",
      "step 486000: average return = -36376.0 cullsteps = 14.5\n",
      "step 487000: average return = -62878.3 cullsteps = 1.7\n",
      "step 488000: average return = -39945.8 cullsteps = 6.2\n",
      "step 489000: average return = -56691.1 cullsteps = 5.2\n",
      "step 490000: average return = -52009.7 cullsteps = 3.8\n",
      "step 491000: average return = -50687.1 cullsteps = 3.9\n",
      "step 492000: average return = -12999.2 cullsteps = 34.3\n",
      "step 493000: average return = -11532.0 cullsteps = 33.6\n",
      "step 494000: average return = -10201.0 cullsteps = 32.4\n",
      "step 495000: average return = -13535.2 cullsteps = 50.6\n",
      "step 496000: average return = -14427.3 cullsteps = 46.4\n",
      "step 497000: average return = -14620.6 cullsteps = 54.8\n",
      "step 498000: average return = -14575.5 cullsteps = 55.4\n",
      "step 499000: average return = -17112.4 cullsteps = 46.5\n",
      "step 500000: average return = -17789.9 cullsteps = 43.3\n",
      "step 501000: average return = -11485.7 cullsteps = 35.4\n",
      "step 502000: average return = -15376.9 cullsteps = 39.6\n",
      "step 503000: average return = -11348.0 cullsteps = 23.6\n",
      "step 504000: average return = -12489.1 cullsteps = 34.2\n",
      "step 505000: average return = -13422.2 cullsteps = 37.1\n",
      "step 506000: average return = -13806.0 cullsteps = 35.3\n",
      "step 507000: average return = -12810.0 cullsteps = 36.3\n",
      "step 508000: average return = -12702.3 cullsteps = 39.7\n",
      "step 509000: average return = -15119.0 cullsteps = 34.7\n",
      "step 510000: average return = -14708.9 cullsteps = 42.4\n",
      "step 511000: average return = -14736.9 cullsteps = 36.5\n",
      "step 512000: average return = -16401.9 cullsteps = 39.7\n",
      "step 513000: average return = -14038.0 cullsteps = 38.0\n",
      "step 514000: average return = -12490.2 cullsteps = 35.1\n",
      "step 515000: average return = -11864.9 cullsteps = 37.8\n",
      "step 516000: average return = -11675.3 cullsteps = 35.9\n",
      "step 517000: average return = -12678.7 cullsteps = 40.5\n",
      "step 518000: average return = -13894.4 cullsteps = 41.8\n",
      "step 519000: average return = -13640.9 cullsteps = 38.3\n",
      "step 520000: average return = -26874.5 cullsteps = 19.6\n",
      "step 521000: average return = -52343.1 cullsteps = 13.1\n",
      "step 522000: average return = -40755.5 cullsteps = 25.6\n",
      "step 523000: average return = -22962.3 cullsteps = 78.7\n",
      "step 524000: average return = -19717.5 cullsteps = 88.4\n",
      "step 525000: average return = -16744.9 cullsteps = 55.1\n",
      "step 526000: average return = -14277.1 cullsteps = 47.0\n",
      "step 527000: average return = -25314.4 cullsteps = 93.1\n",
      "step 528000: average return = -31024.8 cullsteps = 103.3\n",
      "step 529000: average return = -20199.6 cullsteps = 90.3\n",
      "step 530000: average return = -20189.5 cullsteps = 90.4\n"
     ]
    }
   ],
   "source": [
    "train_eval(root_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
