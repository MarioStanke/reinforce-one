{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0574eef1-bdb4-41f0-8073-50c20a190208",
   "metadata": {},
   "source": [
    "## Env Development  \n",
    "This will contain tests for developing environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffc619d0-37c3-47a3-9cbb-98c27e19621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import functools\n",
    "import os\n",
    "import time\n",
    "\n",
    "from absl import app\n",
    "from absl import logging\n",
    "\n",
    "import gin\n",
    "from six.moves import range\n",
    "import tensorflow as tf  # pylint: disable=g-explicit-tensorflow-version-import\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "#plt.ioff() \n",
    "\n",
    "from tf_agents.agents.ddpg import actor_rnn_network\n",
    "from tf_agents.agents.ddpg import critic_rnn_network\n",
    "from tf_agents.agents.ddpg import ddpg_agent\n",
    "from tf_agents.drivers import dynamic_episode_driver\n",
    "from tf_agents.environments import suite_dm_control\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.environments import py_environment\n",
    "from tf_agents.environments import wrappers\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.utils import common\n",
    "\n",
    "import numpy as np\n",
    "from tf_agents.environments import utils\n",
    "from tf_agents.trajectories.time_step import StepType\n",
    "from tf_agents.trajectories import TimeStep\n",
    "from tf_agents.policies import scripted_py_policy\n",
    "from tf_agents.policies import random_py_policy\n",
    "from tf_agents.policies import policy_saver\n",
    "from tf_agents.metrics import py_metrics\n",
    "from tf_agents.drivers import py_driver\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.networks import sequential\n",
    "\n",
    "from Env import Env\n",
    "max_episode_length=1000\n",
    "num_herds = 2\n",
    "total_population = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbeccb84-17d0-42c0-a336-fe9b94747e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "py_env = Env(num_herds = num_herds, total_population = total_population, fix_episode_length=True, average_episode_length = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd1ce9b-cd1c-4aa0-a7de-1409feb35aae",
   "metadata": {},
   "source": [
    "First, test environment input and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd5930af-342d-4875-a6ef-28f89f08dfa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset:  TimeStep(\n",
      "{'discount': 1.0,\n",
      " 'observation': array([0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
      " 'reward': 0.0,\n",
      " 'step_type': array(0, dtype=int32)})\n",
      "Step:  TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([0.01, 0.01, 0.  , 0.  , 0.01, 0.  , 0.  ], dtype=float32),\n",
      " 'reward': array(-1.068593, dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "Step:  TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([0.02, 0.02, 0.  , 0.  , 0.02, 0.  , 0.  ], dtype=float32),\n",
      " 'reward': array(-2.3114612, dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "Step:  TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([0.03, 0.03, 0.  , 0.  , 0.03, 0.  , 0.  ], dtype=float32),\n",
      " 'reward': array(-3.6544127, dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "Step:  TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([0.04      , 0.03      , 0.88666666, 0.11333334, 0.03      ,\n",
      "       0.98      , 0.02      ], dtype=float32),\n",
      " 'reward': array(-5.0605836, dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "Step:  TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([0.05, 0.03, 0.86, 0.14, 0.03, 0.98, 0.02], dtype=float32),\n",
      " 'reward': array(-6.5727563, dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "Step:  TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([0.06      , 0.03      , 0.8666667 , 0.13333334, 0.03      ,\n",
      "       0.94      , 0.06      ], dtype=float32),\n",
      " 'reward': array(-8.214649, dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "Step:  TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([0.07      , 0.03      , 0.8666667 , 0.13333334, 0.03      ,\n",
      "       0.9266667 , 0.07333333], dtype=float32),\n",
      " 'reward': array(-10.174263, dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "Step:  TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([0.08      , 0.03      , 0.8666667 , 0.13333334, 0.03      ,\n",
      "       0.9066667 , 0.09333333], dtype=float32),\n",
      " 'reward': array(-12.312687, dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "Step:  TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([0.09      , 0.03      , 0.85333335, 0.14666666, 0.03      ,\n",
      "       0.9       , 0.1       ], dtype=float32),\n",
      " 'reward': array(-14.550022, dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "Step:  TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([0.1       , 0.03      , 0.82666665, 0.17333333, 0.03      ,\n",
      "       0.88      , 0.12      ], dtype=float32),\n",
      " 'reward': array(-16.888273, dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n"
     ]
    }
   ],
   "source": [
    "zero_step = py_env.reset()\n",
    "print('Reset: ', zero_step)\n",
    "for i in range (0,10):\n",
    "    step = py_env.step([1.,1.,0.,0.])\n",
    "    print('Step: ', step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180fc0e5-420c-4921-83ae-29bba2e1a407",
   "metadata": {},
   "source": [
    "Define two scripted policies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d284752-3370-4a49-b7bd-12b648a7a9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define t\n",
    "\n",
    "action_script1 = [(10, [0,0,0,0]), \n",
    "                 (1, [0,0,1,1]),\n",
    "                 (10, [0,0,0,0]), \n",
    "                 (1, [0,0,1,1])] * int(1+max_episode_length)\n",
    "\n",
    "scr_pol_1 = scripted_py_policy.ScriptedPyPolicy(\n",
    "    time_step_spec=py_env.time_step_spec(),\n",
    "    action_spec=py_env.action_spec(),\n",
    "    action_script=action_script1)\n",
    "\n",
    "action_script2 = [(7, [0,0,0,0]), \n",
    "                 (1, [0,0,1,1]),\n",
    "                 (7, [0,0,0,0]), \n",
    "                 (1, [0,0,1,1])] * int(1+max_episode_length)\n",
    "\n",
    "scr_pol_2 = scripted_py_policy.ScriptedPyPolicy(\n",
    "    time_step_spec=py_env.time_step_spec(),\n",
    "    action_spec=py_env.action_spec(),\n",
    "    action_script=action_script2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b854a6cb-abb4-4208-8efd-3891fd77f04f",
   "metadata": {},
   "source": [
    "And create a random policy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d0bdb49-4691-4eed-9478-b20e23063305",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_policy = random_py_policy.RandomPyPolicy(time_step_spec=py_env.time_step_spec(), \n",
    "                                                action_spec=py_env.action_spec())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d0f36e-9255-4e29-84e0-6fbb2f3463c8",
   "metadata": {},
   "source": [
    "Now write a function that tests an environment with any policy.  \n",
    "Outputs average return over a set number of episodes and average steps where the agent culled one or more herds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0c12c15-4651-46eb-ba8d-976b4f60825e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rnn_env(environment, policy, num_episodes=50):\n",
    "    if isinstance(environment, py_environment.PyEnvironment):\n",
    "        total_return = 0.0\n",
    "        cullsteps = 0 \n",
    "        for e in range(num_episodes):\n",
    "\n",
    "            time_step = environment.reset()\n",
    "            if isinstance(policy, scripted_py_policy.ScriptedPyPolicy):\n",
    "                policy_state = policy.get_initial_state() # remember where in the script we were\n",
    "            else:\n",
    "                #print(policy.get_initial_state(batch_size=train_env.batch_size()))\n",
    "                policy_state = policy.get_initial_state(batch_size=1) # other policies without memory\n",
    "            episode_return = 0.0\n",
    "            i=0\n",
    "            while not time_step.is_last():\n",
    "                i+=1\n",
    "                action_step = policy.action(time_step, policy_state)\n",
    "                for i in range (num_herds, num_herds*2):\n",
    "                    if action_step.action[i] > 0:\n",
    "                        cullsteps += 1\n",
    "                        \n",
    "                policy_state = action_step.state\n",
    "                time_step = environment.step(action_step.action)\n",
    "\n",
    "                episode_return += time_step.reward\n",
    "\n",
    "            total_return += episode_return\n",
    "\n",
    "        avg_return = total_return / num_episodes\n",
    "        cullsteps /= num_episodes\n",
    "        return avg_return, cullsteps\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba504a37-2353-4917-a9b1-1fedb2a417d0",
   "metadata": {},
   "source": [
    "At this point, use the policies for stress testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "914658bd-cdb0-4d92-9ec2-9575f8dec361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average return = -4336.004935503402 cullsteps = 9.0\n"
     ]
    }
   ],
   "source": [
    "avg_return, culls = test_rnn_env(py_env, scr_pol_1, num_episodes = 200)\n",
    "culls /= 2\n",
    "print('average return = {0} cullsteps = {1}'.format(avg_return, culls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51e8955e-fc0e-4a71-bfca-5393e62e2ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average return = -4287.3925736302135 cullsteps = 12.0\n"
     ]
    }
   ],
   "source": [
    "avg_return, culls = test_rnn_env(py_env, scr_pol_2, num_episodes = 200)\n",
    "culls /= 2\n",
    "print('average return = {0} cullsteps = {1}'.format(avg_return, culls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7aa803ed-c4f0-4400-8b2b-5f8aeefdc6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average return = -14365.294085966796 cullsteps = 100.0\n"
     ]
    }
   ],
   "source": [
    "avg_return, culls = test_rnn_env(py_env, random_policy , num_episodes = 200)\n",
    "culls /= 2\n",
    "print('average return = {0} cullsteps = {1}'.format(avg_return, culls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c968435-4e30-4315-8503-1da187ac820c",
   "metadata": {},
   "source": [
    "Additionally, run a Pseudo-Agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0d6edea-d76c-4f99-970f-e2683b8b1872",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def PseudoAgent(env, num_episodes):\n",
    "    assert num_episodes >= 0, \"Please enter a positive integer for episode number.\"\n",
    "    \n",
    "    # Outputs\n",
    "    total_culls_h1 = 0\n",
    "    total_culls_h2 = 0\n",
    "    total_return = 0.\n",
    "    \n",
    "    for i in range (0, num_episodes):\n",
    "        time_step = env.reset()\n",
    "        counter = 0\n",
    "        episode_return = 0.\n",
    "        cw_1 = 0\n",
    "        while not time_step.is_last():\n",
    "            act = [0.,0.,0.,0.]\n",
    "            if counter % 3 == 0:\n",
    "                act[0] = 0.5\n",
    "                act[1] = 0.5\n",
    "            counter += 1\n",
    "            # 3/epl because of 3 weeks until testresults\n",
    "            if (time_step.observation[3] >= 0.07 or time_step.observation[6] >= 0.07) and cw_1 >= 5:\n",
    "                act[2] = 1.\n",
    "                act[3] = 1.\n",
    "                total_culls_h1 += 1\n",
    "                cw_1 = 0\n",
    "            else:\n",
    "                cw_1 += 1\n",
    "            time_step = env.step(act)\n",
    "            episode_return += time_step.reward\n",
    "        total_return += episode_return\n",
    "        \n",
    "    avg_culls_h2 = total_culls_h2 / num_episodes\n",
    "    avg_culls_h1 = total_culls_h1 / num_episodes\n",
    "    avg_return = total_return / num_episodes\n",
    "    return avg_culls_h1, avg_culls_h2, avg_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "329726c6-8999-48e1-9596-03f382cd9712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average culls herd 1:  8.79\n",
      "Average culls herd 2:  0.0\n",
      "Average Return:  -4759.979590873122\n"
     ]
    }
   ],
   "source": [
    "c1,c2,ar = PseudoAgent(py_env, 200)\n",
    "print('Average culls herd 1: ', c1)\n",
    "print('Average culls herd 2: ', c2)\n",
    "print('Average Return: ', ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9e3b81e-0da8-49cf-ac1a-adc3fa2e1282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7b9eaca280>,\n",
       " <matplotlib.lines.Line2D at 0x7f7b9eaca2e0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing whether reward function values make sense\n",
    "cull_cost = 2.5\n",
    "herd_population = 10\n",
    "\n",
    "pop = np.linspace(herd_population*cull_cost,herd_population*cull_cost,num=herd_population)\n",
    "ran = np.arange(0, herd_population, 1)\n",
    "\n",
    "plt.plot(ran, ran*5,'r--', ran, pop,'b--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c256c2c-2a39-4dcd-b022-7c5fadb5739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing reward function for different herd sizes\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
