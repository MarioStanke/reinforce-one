{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0574eef1-bdb4-41f0-8073-50c20a190208",
   "metadata": {},
   "source": [
    "## Env Development  \n",
    "This will contain tests for developing environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffc619d0-37c3-47a3-9cbb-98c27e19621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import functools\n",
    "import os\n",
    "import time\n",
    "\n",
    "from absl import app\n",
    "from absl import logging\n",
    "import sys\n",
    "sys.path.insert(1, '/home/jovyan/Masterarbeit/reinforce-one/Environment/Simplifications')\n",
    "sys.path.insert(1, '/home/jovyan/Masterarbeit/reinforce-one/Environment/Variations')\n",
    "sys.path.insert(1, '/home/jovyan/Masterarbeit/reinforce-one/Agent/DDPG/Test1_Frequent_Returns')\n",
    "\n",
    "import gin\n",
    "from six.moves import range\n",
    "import tensorflow as tf  # pylint: disable=g-explicit-tensorflow-version-import\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "#plt.ioff() \n",
    "\n",
    "from tf_agents.agents.ddpg import actor_rnn_network\n",
    "from tf_agents.agents.ddpg import critic_rnn_network\n",
    "from tf_agents.agents.ddpg import ddpg_agent\n",
    "from tf_agents.drivers import dynamic_episode_driver\n",
    "from tf_agents.environments import suite_dm_control\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.environments import py_environment\n",
    "from tf_agents.environments import wrappers\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.utils import common\n",
    "\n",
    "import numpy as np\n",
    "from tf_agents.environments import utils\n",
    "from tf_agents.trajectories.time_step import StepType\n",
    "from tf_agents.trajectories import TimeStep\n",
    "from tf_agents.policies import scripted_py_policy\n",
    "from tf_agents.policies import random_py_policy\n",
    "from tf_agents.policies import policy_saver\n",
    "from tf_agents.metrics import py_metrics\n",
    "from tf_agents.drivers import py_driver\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.networks import sequential\n",
    "\n",
    "from Env import Env\n",
    "from Env_LS import Env_LS\n",
    "from FR_Env import FREnv\n",
    "from Env_no_tests import Env_NT\n",
    "from Env_Simple import Env_S\n",
    "from Env_S_C import Env_S_C\n",
    "from Env_S_A import Env_S_A\n",
    "from Env_Transfers import Env_T\n",
    "from Env_Cull_Counter import Env_CC\n",
    "\n",
    "max_episode_length=1000\n",
    "num_herds = 2\n",
    "total_population = 300\n",
    "weeks_until_testresults = 0.\n",
    "average_episode_length = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbeccb84-17d0-42c0-a336-fe9b94747e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#py_env = Env_NT(num_herds = num_herds, total_population = total_population, fix_episode_length=True, average_episode_length = 200)\n",
    "py_env = Env(num_herds = num_herds, \n",
    "             total_population = total_population, \n",
    "             fix_episode_length=True, \n",
    "             weeks_until_testresults = weeks_until_testresults,\n",
    "             average_episode_length = average_episode_length)\n",
    "\n",
    "py_env_t = Env_T(num_herds = num_herds,\n",
    "                 total_population = total_population, \n",
    "                 fix_episode_length=True, \n",
    "                 weeks_until_testresults = weeks_until_testresults,\n",
    "                 average_episode_length = average_episode_length)\n",
    "\n",
    "py_env_cc = Env_CC(num_herds = num_herds,\n",
    "                   total_population = total_population, \n",
    "                   fix_episode_length=True, \n",
    "                   weeks_until_testresults = weeks_until_testresults,\n",
    "                   average_episode_length = average_episode_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd1ce9b-cd1c-4aa0-a7de-1409feb35aae",
   "metadata": {},
   "source": [
    "First, test environment input and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd5930af-342d-4875-a6ef-28f89f08dfa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset:  TimeStep(\n",
      "{'discount': 1.0,\n",
      " 'observation': array([0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
      " 'reward': 0.0,\n",
      " 'step_type': array(0, dtype=int32)})\n",
      "Step:  TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([0.005, 0.005, 0.   , 0.   , 0.005, 0.   , 0.   ], dtype=float32),\n",
      " 'reward': array(-0.16, dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "Step:  TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([0.01, 0.01, 0.  , 0.  , 0.01, 0.  , 0.  ], dtype=float32),\n",
      " 'reward': array(-0.17333333, dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "Step:  TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([0.015, 0.015, 0.   , 0.   , 0.015, 0.   , 0.   ], dtype=float32),\n",
      " 'reward': array(-0.17333333, dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "Step:  TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([0.02, 0.02, 0.  , 0.  , 0.02, 0.  , 0.  ], dtype=float32),\n",
      " 'reward': array(-0.18666667, dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "Step:  TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([0.025, 0.025, 0.   , 0.   , 0.025, 0.   , 0.   ], dtype=float32),\n",
      " 'reward': array(-0.2, dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "Step:  TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([0.03, 0.03, 0.  , 0.  , 0.03, 0.  , 0.  ], dtype=float32),\n",
      " 'reward': array(-0.22666667, dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "Step:  TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([0.035, 0.035, 0.   , 0.   , 0.035, 0.   , 0.   ], dtype=float32),\n",
      " 'reward': array(-0.24, dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "Step:  TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([0.04, 0.04, 0.  , 0.  , 0.04, 0.  , 0.  ], dtype=float32),\n",
      " 'reward': array(-0.26666668, dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "Step:  TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([0.045     , 0.04499999, 0.        , 0.        , 0.04499999,\n",
      "       0.        , 0.        ], dtype=float32),\n",
      " 'reward': array(-0.29333332, dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "Step:  TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([0.05      , 0.04999999, 0.        , 0.        , 0.04999999,\n",
      "       0.        , 0.        ], dtype=float32),\n",
      " 'reward': array(-0.36, dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n"
     ]
    }
   ],
   "source": [
    "if(num_herds==2):\n",
    "    zero_step = py_env.reset()\n",
    "    print('Reset: ', zero_step)\n",
    "    for i in range (0,10):\n",
    "        step = py_env.step([0.,0.,0.,0.])\n",
    "        print('Step: ', step)\n",
    "else:\n",
    "    print('Not for more than 2 herds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180fc0e5-420c-4921-83ae-29bba2e1a407",
   "metadata": {},
   "source": [
    "Define two scripted policies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d284752-3370-4a49-b7bd-12b648a7a9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'action_script1 = [(5, [0,0]), \\n                 (1, [1,1]),\\n                 (5, [0,0]), \\n                 (1, [1,1])] * int(1+max_episode_length)\\n\\nscr_pol_1 = scripted_py_policy.ScriptedPyPolicy(\\n    time_step_spec=py_env.time_step_spec(),\\n    action_spec=py_env.action_spec(),\\n    action_script=action_script1)\\n\\naction_script2 = [(6, [0,0]), \\n                 (1, [1,1]),\\n                 (6, [0,0]), \\n                 (1, [1,1])] * int(1+max_episode_length)\\n\\nscr_pol_2 = scripted_py_policy.ScriptedPyPolicy(\\n    time_step_spec=py_env.time_step_spec(),\\n    action_spec=py_env.action_spec(),\\n    action_script=action_script2)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_script1 = [(16, [0,0,0,0]), \n",
    "                 (1, [0,0,1,1]),\n",
    "                 (16, [0,0,0,0]), \n",
    "                 (1, [0,0,1,1])] * int(1+max_episode_length)\n",
    "\n",
    "scr_pol_1 = scripted_py_policy.ScriptedPyPolicy(\n",
    "    time_step_spec=py_env.time_step_spec(),\n",
    "    action_spec=py_env.action_spec(),\n",
    "    action_script=action_script1)\n",
    "\n",
    "action_script2 = [(17, [0,0,0,0]), \n",
    "                 (1, [0,0,1,1]),\n",
    "                 (17, [0,0,0,0]), \n",
    "                 (1, [0,0,1,1])] * int(1+max_episode_length)\n",
    "\n",
    "scr_pol_2 = scripted_py_policy.ScriptedPyPolicy(\n",
    "    time_step_spec=py_env.time_step_spec(),\n",
    "    action_spec=py_env.action_spec(),\n",
    "    action_script=action_script2)\n",
    "\n",
    "'''action_script1 = [(5, [0,0]), \n",
    "                 (1, [1,1]),\n",
    "                 (5, [0,0]), \n",
    "                 (1, [1,1])] * int(1+max_episode_length)\n",
    "\n",
    "scr_pol_1 = scripted_py_policy.ScriptedPyPolicy(\n",
    "    time_step_spec=py_env.time_step_spec(),\n",
    "    action_spec=py_env.action_spec(),\n",
    "    action_script=action_script1)\n",
    "\n",
    "action_script2 = [(6, [0,0]), \n",
    "                 (1, [1,1]),\n",
    "                 (6, [0,0]), \n",
    "                 (1, [1,1])] * int(1+max_episode_length)\n",
    "\n",
    "scr_pol_2 = scripted_py_policy.ScriptedPyPolicy(\n",
    "    time_step_spec=py_env.time_step_spec(),\n",
    "    action_spec=py_env.action_spec(),\n",
    "    action_script=action_script2)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b854a6cb-abb4-4208-8efd-3891fd77f04f",
   "metadata": {},
   "source": [
    "And create a random policy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d0bdb49-4691-4eed-9478-b20e23063305",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_policy = random_py_policy.RandomPyPolicy(time_step_spec=py_env.time_step_spec(), \n",
    "                                                action_spec=py_env.action_spec())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d0f36e-9255-4e29-84e0-6fbb2f3463c8",
   "metadata": {},
   "source": [
    "Now write a function that tests an environment with any policy.  \n",
    "Outputs average return over a set number of episodes and average steps where the agent culled one or more herds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0c12c15-4651-46eb-ba8d-976b4f60825e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rnn_env(environment, policy, num_episodes = 50, num_herds = 2):\n",
    "    if isinstance(environment, py_environment.PyEnvironment):\n",
    "        total_return = 0.0\n",
    "        cullsteps = 0 \n",
    "        if environment.action_spec().shape[0] == num_herds:\n",
    "            only_culls = True\n",
    "        else:\n",
    "            only_culls = False\n",
    "        for e in range(num_episodes):\n",
    "\n",
    "            time_step = environment.reset()\n",
    "            if isinstance(policy, scripted_py_policy.ScriptedPyPolicy):\n",
    "                policy_state = policy.get_initial_state() # remember where in the script we were\n",
    "            else:\n",
    "                #print(policy.get_initial_state(batch_size=train_env.batch_size()))\n",
    "                policy_state = policy.get_initial_state(batch_size=1) # other policies without memory\n",
    "            episode_return = 0.0\n",
    "            i=0\n",
    "            while not time_step.is_last():\n",
    "                i+=1\n",
    "                action_step = policy.action(time_step, policy_state)\n",
    "                if only_culls:\n",
    "                    for j in range (0, num_herds):\n",
    "                        if action_step.action[j] >= 0.5:\n",
    "                            cullsteps += 1\n",
    "                else:\n",
    "                    for j in range (num_herds, num_herds*2):\n",
    "                        if action_step.action[j] >= 0.5:\n",
    "                            cullsteps += 1\n",
    "                policy_state = action_step.state\n",
    "                time_step = environment.step(action_step.action)\n",
    "\n",
    "                episode_return += time_step.reward\n",
    "\n",
    "            total_return += episode_return\n",
    "        avg_return = total_return / num_episodes\n",
    "        cullsteps /= num_episodes\n",
    "        return avg_return, cullsteps\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba504a37-2353-4917-a9b1-1fedb2a417d0",
   "metadata": {},
   "source": [
    "At this point, use the policies for stress testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "914658bd-cdb0-4d92-9ec2-9575f8dec361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average return = -32.755866742366926 cullsteps = 11.0\n"
     ]
    }
   ],
   "source": [
    "if(num_herds == 2):\n",
    "    avg_return, culls = test_rnn_env(py_env, scr_pol_1, num_episodes = 200)\n",
    "    culls /= 2\n",
    "    print('average return = {0} cullsteps = {1}'.format(avg_return, culls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51e8955e-fc0e-4a71-bfca-5393e62e2ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average return = -34.05886674197391 cullsteps = 11.0\n"
     ]
    }
   ],
   "source": [
    "if(num_herds == 2):\n",
    "    avg_return, culls = test_rnn_env(py_env, scr_pol_2, num_episodes = 200)\n",
    "    culls /= 2\n",
    "    print('average return = {0} cullsteps = {1}'.format(avg_return, culls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b62c9d6d-19ca-44ee-81cf-f1f2fc4f4219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average return = -199.67128115974018 cullsteps = 99.255\n"
     ]
    }
   ],
   "source": [
    "avg_return, culls = test_rnn_env(py_env, random_policy , num_episodes = 100)\n",
    "culls /= 2\n",
    "print('average return = {0} cullsteps = {1}'.format(avg_return, culls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c968435-4e30-4315-8503-1da187ac820c",
   "metadata": {},
   "source": [
    "Additionally, run a Pseudo-Agent. Currently only works for 2 Herds / Actions with test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0d6edea-d76c-4f99-970f-e2683b8b1872",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def PseudoAgent(env, num_episodes):\n",
    "    assert num_episodes >= 0, \"Please enter a positive integer for episode number.\"\n",
    "    # Outputs\n",
    "    total_culls = np.zeros((num_herds,), np.int32)\n",
    "    total_return = 0.\n",
    "    testresults_time = weeks_until_testresults / average_episode_length\n",
    "    \n",
    "    for i in range (0, num_episodes):\n",
    "        time_step = env.reset()\n",
    "        episode_return = 0.\n",
    "        \n",
    "        while not time_step.is_last():\n",
    "            cull_all = False\n",
    "            act = np.zeros((num_herds*2,), np.float32)\n",
    "            for k in range (0, num_herds):\n",
    "                act[k] = 0.5\n",
    "            for l in range (0, num_herds):\n",
    "                if (np.float32(time_step.observation[(l+1)*3]) >= np.float32(0.1) \n",
    "                    and np.float32(time_step.observation[((l+1)*3)-2]) == np.float32(testresults_time)):\n",
    "                    cull_all = True\n",
    "                    break\n",
    "            if cull_all:\n",
    "                for j in range (num_herds,num_herds*2):\n",
    "                    act[j] = 1.\n",
    "                    total_culls[j-num_herds] += 1\n",
    "            time_step = env.step(act)\n",
    "            episode_return += time_step.reward\n",
    "        total_return += episode_return\n",
    "        \n",
    "    culls = np.sum(total_culls) / num_episodes\n",
    "    avg_return = total_return / num_episodes\n",
    "    return culls, avg_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf51af69-d128-4621-a3b6-7bba6cc5987d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def PseudoAgent2(env, num_episodes):\n",
    "    assert num_episodes >= 0, \"Please enter a positive integer for episode number.\"\n",
    "    # Outputs\n",
    "    total_culls = np.zeros((num_herds,), np.int32)\n",
    "    total_return = 0.\n",
    "    testresults_time = weeks_until_testresults / average_episode_length\n",
    "    \n",
    "    for i in range (0, num_episodes):\n",
    "        time_step = env.reset()\n",
    "        episode_return = 0.\n",
    "        \n",
    "        while not time_step.is_last():\n",
    "            act = np.zeros((num_herds*2,), np.float32)\n",
    "            for k in range (0, num_herds):\n",
    "                act[k] = 0.5\n",
    "            for l in range (0, num_herds):\n",
    "                if (np.float32(time_step.observation[(l+1)*3]) >= np.float32(0.1) \n",
    "                    and np.float32(time_step.observation[((l+1)*3)-2]) == np.float32(testresults_time)):\n",
    "                    act[l+num_herds] = 1.\n",
    "                    total_culls[l] += 1\n",
    "            time_step = env.step(act)\n",
    "            episode_return += time_step.reward\n",
    "        total_return += episode_return\n",
    "        \n",
    "    culls = np.sum(total_culls) / num_episodes\n",
    "    avg_return = total_return / num_episodes\n",
    "    return culls, avg_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b101acc4-bb08-430f-ae3d-b5f6d1f4a04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Culls per Episode:  13.236\n",
      "Average Return:  -30.62954714883212\n"
     ]
    }
   ],
   "source": [
    "c , ar = PseudoAgent(py_env, 500)\n",
    "print('Average Culls per Episode: ', c)\n",
    "print('Average Return: ', ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "998fdded-9aae-4c79-8f4c-7b020a808da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Culls per Episode:  13.472\n",
      "Average Return:  -30.255493829206564\n"
     ]
    }
   ],
   "source": [
    "c , ar = PseudoAgent(py_env_t, 500)\n",
    "print('Average Culls per Episode: ', c)\n",
    "print('Average Return: ', ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ad795ff-d876-41a0-8e46-772434250e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Culls per Episode:  13.204\n",
      "Average Return:  -30.925520241813736\n"
     ]
    }
   ],
   "source": [
    "c , ar = PseudoAgent(py_env_cc, 500)\n",
    "print('Average Culls per Episode: ', c)\n",
    "print('Average Return: ', ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "743ad1bd-1d59-47fe-89c3-bf8cd7f9b6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Culls per Episode:  14.052\n",
      "Average Return:  -40.44474675542582\n"
     ]
    }
   ],
   "source": [
    "c, ar = PseudoAgent2(py_env, 500)\n",
    "print('Average Culls per Episode: ', c)\n",
    "print('Average Return: ', ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3afc7c-ef04-4a34-ac8e-7133b6e9a044",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
