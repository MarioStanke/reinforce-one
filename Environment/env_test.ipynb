{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0574eef1-bdb4-41f0-8073-50c20a190208",
   "metadata": {},
   "source": [
    "## Env Development  \n",
    "This will contain tests for developing environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffc619d0-37c3-47a3-9cbb-98c27e19621b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import functools\n",
    "import os\n",
    "import time\n",
    "\n",
    "from absl import app\n",
    "from absl import logging\n",
    "import sys\n",
    "sys.path.insert(1, '/home/jovyan/Masterarbeit/reinforce-one/Environment/Simplifications')\n",
    "sys.path.insert(1, '/home/jovyan/Masterarbeit/reinforce-one/Environment/Variations')\n",
    "sys.path.insert(1, '/home/jovyan/Masterarbeit/reinforce-one/Agent/DDPG/Test1_Frequent_Returns')\n",
    "\n",
    "import gin\n",
    "from six.moves import range\n",
    "import tensorflow as tf  # pylint: disable=g-explicit-tensorflow-version-import\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "#plt.ioff() \n",
    "\n",
    "from tf_agents.agents.ddpg import actor_rnn_network\n",
    "from tf_agents.agents.ddpg import critic_rnn_network\n",
    "from tf_agents.agents.ddpg import ddpg_agent\n",
    "from tf_agents.drivers import dynamic_episode_driver\n",
    "from tf_agents.environments import suite_dm_control\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.environments import py_environment\n",
    "from tf_agents.environments import wrappers\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.utils import common\n",
    "\n",
    "import numpy as np\n",
    "from tf_agents.environments import utils\n",
    "from tf_agents.trajectories.time_step import StepType\n",
    "from tf_agents.trajectories import TimeStep\n",
    "from tf_agents.policies import scripted_py_policy\n",
    "from tf_agents.policies import random_py_policy\n",
    "from tf_agents.policies import policy_saver\n",
    "from tf_agents.metrics import py_metrics\n",
    "from tf_agents.drivers import py_driver\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.networks import sequential\n",
    "\n",
    "from Env import Env\n",
    "from Env_No_GT import Env_No_GT\n",
    "from Env_TSLC import Env_TSLC\n",
    "from Env_LS import Env_LS\n",
    "from FR_Env import FREnv\n",
    "from Env_no_tests import Env_NT\n",
    "from Env_Simple import Env_S\n",
    "from Env_S_C import Env_S_C\n",
    "from Env_S_A import Env_S_A\n",
    "from Env_Transfers import Env_T\n",
    "from Env_Cull_Counter import Env_CC\n",
    "from Env_Complexity import Env_Comp\n",
    "\n",
    "max_episode_length=1000\n",
    "num_herds = 2\n",
    "total_population = 300\n",
    "weeks_until_testresults = 0.\n",
    "average_episode_length = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbeccb84-17d0-42c0-a336-fe9b94747e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npy_env_t = Env_T(num_herds = num_herds,\\n                 total_population = total_population, \\n                 fix_episode_length=True, \\n                 weeks_until_testresults = weeks_until_testresults,\\n                 average_episode_length = average_episode_length)\\n\\npy_env_cc = Env_CC(num_herds = num_herds,\\n                   total_population = total_population, \\n                   fix_episode_length=True, \\n                   weeks_until_testresults = weeks_until_testresults,\\n                   average_episode_length = average_episode_length)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#py_env = Env_NT(num_herds = num_herds, total_population = total_population, fix_episode_length=True, average_episode_length = 200)\n",
    "py_env = Env_TSLC(num_herds = num_herds, \n",
    "             total_population = total_population, \n",
    "             fix_episode_length=True, \n",
    "             weeks_until_testresults = weeks_until_testresults,\n",
    "             average_episode_length = average_episode_length)\n",
    "\n",
    "py_env_comp = Env_Comp(num_herds = num_herds,\n",
    "                 total_population = total_population, \n",
    "                 fix_episode_length=True, \n",
    "                 weeks_until_testresults = weeks_until_testresults,\n",
    "                 average_episode_length = average_episode_length)\n",
    "\n",
    "'''\n",
    "py_env_t = Env_T(num_herds = num_herds,\n",
    "                 total_population = total_population, \n",
    "                 fix_episode_length=True, \n",
    "                 weeks_until_testresults = weeks_until_testresults,\n",
    "                 average_episode_length = average_episode_length)\n",
    "\n",
    "py_env_cc = Env_CC(num_herds = num_herds,\n",
    "                   total_population = total_population, \n",
    "                   fix_episode_length=True, \n",
    "                   weeks_until_testresults = weeks_until_testresults,\n",
    "                   average_episode_length = average_episode_length)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd1ce9b-cd1c-4aa0-a7de-1409feb35aae",
   "metadata": {},
   "source": [
    "First, test environment input and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd5930af-342d-4875-a6ef-28f89f08dfa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset:  TimeStep(\n",
      "{'discount': 1.0,\n",
      " 'observation': array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
      " 'reward': 0.0,\n",
      " 'step_type': array(0, dtype=int32)})\n",
      "Step:  TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([0.005, 0.   , 0.   , 0.005, 0.005, 0.   , 0.   , 0.005],\n",
      "      dtype=float32),\n",
      " 'reward': array(-0.18666667, dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "Step:  TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([0.01, 0.  , 0.  , 0.01, 0.01, 0.  , 0.  , 0.01], dtype=float32),\n",
      " 'reward': array(-0.21333334, dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "Step:  TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([0.015, 0.   , 0.   , 0.015, 0.015, 0.   , 0.   , 0.015],\n",
      "      dtype=float32),\n",
      " 'reward': array(-0.25333333, dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "Step:  TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([0.02, 0.  , 0.  , 0.02, 0.02, 0.  , 0.  , 0.02], dtype=float32),\n",
      " 'reward': array(-0.26666668, dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "Step:  TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([0.025, 0.   , 0.   , 0.025, 0.025, 0.   , 0.   , 0.025],\n",
      "      dtype=float32),\n",
      " 'reward': array(-0.29333332, dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "Step:  TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([0.03, 0.  , 0.  , 0.03, 0.03, 0.  , 0.  , 0.03], dtype=float32),\n",
      " 'reward': array(-0.33333334, dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "Step:  TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([0.035, 0.   , 0.   , 0.035, 0.035, 0.   , 0.   , 0.035],\n",
      "      dtype=float32),\n",
      " 'reward': array(-0.36, dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "Step:  TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([0.04, 0.  , 0.  , 0.04, 0.04, 0.  , 0.  , 0.04], dtype=float32),\n",
      " 'reward': array(-0.42666668, dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "Step:  TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([0.04499999, 0.        , 0.        , 0.04499999, 0.04499999,\n",
      "       0.        , 0.        , 0.04499999], dtype=float32),\n",
      " 'reward': array(-0.42666668, dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n",
      "Step:  TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': array([0.04999999, 0.        , 0.        , 0.04999999, 0.04999999,\n",
      "       0.        , 0.        , 0.04999999], dtype=float32),\n",
      " 'reward': array(-0.48, dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n"
     ]
    }
   ],
   "source": [
    "if(num_herds==2):\n",
    "    zero_step = py_env.reset()\n",
    "    print('Reset: ', zero_step)\n",
    "    for i in range (0,10):\n",
    "        step = py_env.step([0.,0.,0.,0.])\n",
    "        print('Step: ', step)\n",
    "else:\n",
    "    print('Not for more than 2 herds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180fc0e5-420c-4921-83ae-29bba2e1a407",
   "metadata": {},
   "source": [
    "Define two scripted policies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d284752-3370-4a49-b7bd-12b648a7a9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'action_script1 = [(5, [0,0]), \\n                 (1, [1,1]),\\n                 (5, [0,0]), \\n                 (1, [1,1])] * int(1+max_episode_length)\\n\\nscr_pol_1 = scripted_py_policy.ScriptedPyPolicy(\\n    time_step_spec=py_env.time_step_spec(),\\n    action_spec=py_env.action_spec(),\\n    action_script=action_script1)\\n\\naction_script2 = [(6, [0,0]), \\n                 (1, [1,1]),\\n                 (6, [0,0]), \\n                 (1, [1,1])] * int(1+max_episode_length)\\n\\nscr_pol_2 = scripted_py_policy.ScriptedPyPolicy(\\n    time_step_spec=py_env.time_step_spec(),\\n    action_spec=py_env.action_spec(),\\n    action_script=action_script2)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_script1 = [(16, [0,0,0,0]), \n",
    "                 (1, [0,0,1,1]),\n",
    "                 (16, [0,0,0,0]), \n",
    "                 (1, [0,0,1,1])] * int(1+max_episode_length)\n",
    "\n",
    "scr_pol_1 = scripted_py_policy.ScriptedPyPolicy(\n",
    "    time_step_spec=py_env.time_step_spec(),\n",
    "    action_spec=py_env.action_spec(),\n",
    "    action_script=action_script1)\n",
    "\n",
    "action_script2 = [(17, [0,0,0,0]), \n",
    "                 (1, [0,0,1,1]),\n",
    "                 (17, [0,0,0,0]), \n",
    "                 (1, [0,0,1,1])] * int(1+max_episode_length)\n",
    "\n",
    "scr_pol_2 = scripted_py_policy.ScriptedPyPolicy(\n",
    "    time_step_spec=py_env.time_step_spec(),\n",
    "    action_spec=py_env.action_spec(),\n",
    "    action_script=action_script2)\n",
    "\n",
    "'''action_script1 = [(5, [0,0]), \n",
    "                 (1, [1,1]),\n",
    "                 (5, [0,0]), \n",
    "                 (1, [1,1])] * int(1+max_episode_length)\n",
    "\n",
    "scr_pol_1 = scripted_py_policy.ScriptedPyPolicy(\n",
    "    time_step_spec=py_env.time_step_spec(),\n",
    "    action_spec=py_env.action_spec(),\n",
    "    action_script=action_script1)\n",
    "\n",
    "action_script2 = [(6, [0,0]), \n",
    "                 (1, [1,1]),\n",
    "                 (6, [0,0]), \n",
    "                 (1, [1,1])] * int(1+max_episode_length)\n",
    "\n",
    "scr_pol_2 = scripted_py_policy.ScriptedPyPolicy(\n",
    "    time_step_spec=py_env.time_step_spec(),\n",
    "    action_spec=py_env.action_spec(),\n",
    "    action_script=action_script2)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b854a6cb-abb4-4208-8efd-3891fd77f04f",
   "metadata": {},
   "source": [
    "And create a random policy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d0bdb49-4691-4eed-9478-b20e23063305",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_policy = random_py_policy.RandomPyPolicy(time_step_spec=py_env.time_step_spec(), \n",
    "                                                action_spec=py_env.action_spec())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d0f36e-9255-4e29-84e0-6fbb2f3463c8",
   "metadata": {},
   "source": [
    "Now write a function that tests an environment with any policy.  \n",
    "Outputs average return over a set number of episodes and average steps where the agent culled one or more herds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0c12c15-4651-46eb-ba8d-976b4f60825e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_env(environment, policy, num_episodes = 50, num_herds = 2):\n",
    "    if isinstance(environment, py_environment.PyEnvironment):\n",
    "        total_return = []\n",
    "        culls = 0 \n",
    "        if environment.action_spec().shape[0] == num_herds:\n",
    "            only_culls = True\n",
    "        else:\n",
    "            only_culls = False\n",
    "        for e in range(num_episodes):\n",
    "\n",
    "            time_step = environment.reset()\n",
    "            if isinstance(policy, scripted_py_policy.ScriptedPyPolicy):\n",
    "                policy_state = policy.get_initial_state() # remember where in the script we were\n",
    "            else:\n",
    "                #print(policy.get_initial_state(batch_size=train_env.batch_size()))\n",
    "                policy_state = policy.get_initial_state(batch_size=1) # other policies without memory\n",
    "            episode_return = 0.0\n",
    "            i=0\n",
    "            while not time_step.is_last():\n",
    "                i+=1\n",
    "                action_step = policy.action(time_step, policy_state)\n",
    "                if only_culls:\n",
    "                    for j in range (0, num_herds):\n",
    "                        if action_step.action[j] >= 0.5:\n",
    "                            culls += 1\n",
    "                else:\n",
    "                    for j in range (num_herds, num_herds*2):\n",
    "                        if action_step.action[j] >= 0.5:\n",
    "                            culls += 1\n",
    "                policy_state = action_step.state\n",
    "                time_step = environment.step(action_step.action)\n",
    "\n",
    "                episode_return += time_step.reward\n",
    "\n",
    "            total_return.append(episode_return)\n",
    "        culls /= num_episodes\n",
    "        average_return = np.average(total_return)\n",
    "        variance = np.var(total_return)\n",
    "        standard_deviation = np.std(total_return)\n",
    "        return culls, average_return, variance, standard_deviation\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba504a37-2353-4917-a9b1-1fedb2a417d0",
   "metadata": {},
   "source": [
    "At this point, use the policies for stress testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "914658bd-cdb0-4d92-9ec2-9575f8dec361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average return = -37.02406674981117 culls = 22.0\n"
     ]
    }
   ],
   "source": [
    "if(num_herds == 2):\n",
    "    culls, avg_return, var, std = test_env(py_env, scr_pol_1, num_episodes = 200)\n",
    "    print('average return = {0} culls = {1}'.format(avg_return, culls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51e8955e-fc0e-4a71-bfca-5393e62e2ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average return = -38.39833341243677 culls = 22.0\n"
     ]
    }
   ],
   "source": [
    "if(num_herds == 2):\n",
    "    culls, avg_return, var, std = test_env(py_env, scr_pol_2, num_episodes = 200)\n",
    "    print('average return = {0} culls = {1}'.format(avg_return, culls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b62c9d6d-19ca-44ee-81cf-f1f2fc4f4219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average return = -201.52542569446493 culls = 200.06\n"
     ]
    }
   ],
   "source": [
    "culls, avg_return, var, std = test_env(py_env, random_policy , num_episodes = 100)\n",
    "print('average return = {0} culls = {1}'.format(avg_return, culls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c968435-4e30-4315-8503-1da187ac820c",
   "metadata": {},
   "source": [
    "Additionally, run a Pseudo-Agent. Currently only works for 2 Herds / Actions with test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0d6edea-d76c-4f99-970f-e2683b8b1872",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def PseudoAgent(env, num_episodes, cull_threshhold = 0.08):\n",
    "    assert num_episodes >= 0, \"Please enter a positive integer for episode number.\"\n",
    "    # Outputs\n",
    "    total_culls = np.zeros((num_herds,), np.int32)\n",
    "    total_return = []\n",
    "    testresults_time = weeks_until_testresults / average_episode_length\n",
    "    \n",
    "    for i in range (0, num_episodes):\n",
    "        time_step = env.reset()\n",
    "        episode_return = 0.\n",
    "        \n",
    "        while not time_step.is_last():\n",
    "            cull_all = False\n",
    "            act = np.zeros((num_herds*2,), np.float32)\n",
    "            for k in range (0, num_herds):\n",
    "                act[k] = 0.5\n",
    "            for l in range (0, num_herds):\n",
    "                if (np.float32(time_step.observation[(l*4)+2]) >= np.float32(cull_threshhold) \n",
    "                    and np.float32(time_step.observation[(l*4)]) == np.float32(testresults_time)):\n",
    "                    cull_all = True\n",
    "                    break\n",
    "            if cull_all:\n",
    "                for j in range (num_herds,num_herds*2):\n",
    "                    act[j] = 1.\n",
    "                    total_culls[j-num_herds] += 1\n",
    "            time_step = env.step(act)\n",
    "            episode_return += time_step.reward\n",
    "        total_return.append(episode_return)\n",
    "        \n",
    "    culls = np.sum(total_culls) / num_episodes\n",
    "    average_return = np.average(total_return)\n",
    "    variance = np.var(total_return)\n",
    "    standard_deviation = np.std(total_return)\n",
    "    return culls, average_return, variance, standard_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf51af69-d128-4621-a3b6-7bba6cc5987d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def PseudoAgent2(env, num_episodes, cull_threshhold = 0.04):\n",
    "    assert num_episodes >= 0, \"Please enter a positive integer for episode number.\"\n",
    "    # Outputs\n",
    "    total_culls = np.zeros((num_herds,), np.int32)\n",
    "    total_return = []\n",
    "    testresults_time = weeks_until_testresults / average_episode_length\n",
    "    \n",
    "    for i in range (0, num_episodes):\n",
    "        time_step = env.reset()\n",
    "        episode_return = 0.\n",
    "        \n",
    "        while not time_step.is_last():\n",
    "            act = np.zeros((num_herds*2,), np.float32)\n",
    "            for k in range (0, num_herds):\n",
    "                act[k] = 0.5\n",
    "            for l in range (0, num_herds):\n",
    "                if (np.float32(time_step.observation[(l*4)+2]) >= np.float32(cull_threshhold) \n",
    "                    and np.float32(time_step.observation[(l*4)]) == np.float32(testresults_time)):\n",
    "                    act[l+num_herds] = 1.\n",
    "                    total_culls[l] += 1\n",
    "            time_step = env.step(act)\n",
    "            episode_return += time_step.reward\n",
    "        total_return.append(episode_return)\n",
    "        \n",
    "    culls = np.sum(total_culls) / num_episodes\n",
    "    average_return = np.average(total_return)\n",
    "    variance = np.var(total_return)\n",
    "    standard_deviation = np.std(total_return)\n",
    "    return culls, average_return, variance, standard_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b101acc4-bb08-430f-ae3d-b5f6d1f4a04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Culls per Episode:  21.612\n",
      "Average Return:  -32.78680077647604\n",
      "Variance:  6.688213308973516\n",
      "Standard Deviation:  2.5861580208822343\n"
     ]
    }
   ],
   "source": [
    "c , ar, var, std = PseudoAgent(py_env, 500, 0.054)  #0.054 ~ 0.056 optimal\n",
    "print('Average Culls per Episode: ', c)\n",
    "print('Average Return: ', ar)\n",
    "print('Variance: ', var)\n",
    "print('Standard Deviation: ', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "998fdded-9aae-4c79-8f4c-7b020a808da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Culls per Episode:  22.856\n",
      "Average Return:  -30.80808030181099\n",
      "Variance:  7.020365043847092\n",
      "Standard Deviation:  2.649597147463571\n"
     ]
    }
   ],
   "source": [
    "c, ar, var, std = PseudoAgent2(py_env, 500, 0.03) #0.03~0.04 optimal\n",
    "print('Average Culls per Episode: ', c)\n",
    "print('Average Return: ', ar)\n",
    "print('Variance: ', var)\n",
    "print('Standard Deviation: ', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ad795ff-d876-41a0-8e46-772434250e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Culls per Episode:  17.088\n",
      "Average Return:  -34.40010728826746\n",
      "Variance:  6.939945460426102\n",
      "Standard Deviation:  2.6343776229739926\n"
     ]
    }
   ],
   "source": [
    "c , ar, var, std = PseudoAgent(py_env_comp, 500, 0.1)\n",
    "print('Average Culls per Episode: ', c)\n",
    "print('Average Return: ', ar)\n",
    "print('Variance: ', var)\n",
    "print('Standard Deviation: ', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "743ad1bd-1d59-47fe-89c3-bf8cd7f9b6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Culls per Episode:  19.612\n",
      "Average Return:  -30.82821360109933\n",
      "Variance:  7.143349462933075\n",
      "Standard Deviation:  2.672704522189663\n"
     ]
    }
   ],
   "source": [
    "c , ar, var, std = PseudoAgent2(py_env_comp, 500, 0.05)\n",
    "print('Average Culls per Episode: ', c)\n",
    "print('Average Return: ', ar)\n",
    "print('Variance: ', var)\n",
    "print('Standard Deviation: ', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d3afc7c-ef04-4a34-ac8e-7133b6e9a044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AR 1 List after first run:  [-73.76264784749812, -44.85519610775271, -36.5507237314838, -36.62460640086178, -33.677616885660406, -32.88142478070222, -33.127912705389875, -33.204814040013034, -33.99811531717917, -35.196133936884344, -36.6786458931746]\n",
      "CT 1 List after first run:  0.060000000000000005\n",
      "AR 2 List after first run:  [-47.635985893533096, -33.91833353169542, -30.82781630076915, -30.809560304655413, -31.123925597058424, -32.600562858899586, -34.73141880855597, -34.64338413858498, -37.20374677447276, -40.018970756269525, -42.843850736088676]\n",
      "CT 2 List after first run:  0.04\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ct1_max' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-96bcda5c26b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AR 2 List after first run: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marl2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CT 2 List after first run: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mct2m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mct1_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mct1_max\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mct1_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mct1_max\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mct2_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mct2_max\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ct1_max' is not defined"
     ]
    }
   ],
   "source": [
    "# Optimize PAs\n",
    "\n",
    "def optimize_PAs(ct_start = 0.01, ct_end = 0.2, steps = 0.01, environment = py_env, num_episodes = 200):\n",
    "    ar_list_1 = []\n",
    "    ar_list_2 = []\n",
    "    not_end = True\n",
    "    i = ct_start\n",
    "    while not_end:\n",
    "        if i >= (ct_end):\n",
    "            not_end = False\n",
    "\n",
    "        c, ar1, var, std = PseudoAgent(environment, num_episodes, i)\n",
    "        c, ar2, var, std = PseudoAgent2(environment, num_episodes, i)\n",
    "        ar_list_1.append(ar1)\n",
    "        ar_list_2.append(ar2)\n",
    "        i += steps\n",
    "\n",
    "    ar_max = np.amax(ar_list_1)\n",
    "    max_index = ar_list_1.index(ar_max)\n",
    "    ct1_max = ct_start + (steps * max_index)\n",
    "    ar_max = np.amax(ar_list_2)\n",
    "    max_index = ar_list_2.index(ar_max)\n",
    "    ct2_max = ct_start + (steps * max_index)\n",
    "    \n",
    "    return ar_list_1, ar_list_2, ct1_max, ct2_max\n",
    "\n",
    "arl1, arl2, ct1m, ct2m = optimize_PAs(0.01, 0.1, 0.01, py_env, 5000)\n",
    "print('AR 1 List after first run: ', arl1)\n",
    "print('CT 1 List after first run: ', ct1m)\n",
    "print('AR 2 List after first run: ', arl2)\n",
    "print('CT 2 List after first run: ', ct2m)\n",
    "ct1_start = ct1m - (3*0.01)\n",
    "ct1_end = ct1m + (3*0.01)\n",
    "ct2_start = ct2m - (3*0.01)\n",
    "ct2_end = ct2m + (3*0.01)\n",
    "\n",
    "arl1, arl2, ct1m, ct2m = optimize_PAs(ct1_start, ct1_end, 0.001, py_env, 5000)\n",
    "ar_max = np.amax(arl1)\n",
    "max_index = arl1.index(ar_max)\n",
    "low = max_index - 5\n",
    "high = max_index + 5\n",
    "print('Range of high ARs after 2nd run: ', arl1[low:high])\n",
    "print('CT of center Value: ', ct1m)\n",
    "\n",
    "arl1, arl2, ct1m, ct2m = optimize_PAs(ct2_start, ct2_end, 0.001, py_env, 5000)\n",
    "ar_max = np.amax(arl2)\n",
    "max_index = arl2.index(ar_max)\n",
    "low = max_index - 5\n",
    "high = max_index + 5\n",
    "print('Range of high ARs for PA 2: ', arl2[low:high])\n",
    "print('CT of center Value: ', ct2m)\n",
    "    \n",
    "ar_max = np.amax(arl1)\n",
    "max_index = arl1.index(ar_max)\n",
    "low = max_index - 5\n",
    "high = max_index + 5\n",
    "print('Range of high ARs after third run: ', arl1[low:high])\n",
    "print('CT of center Value after third run: ', ct1m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df5b900-8959-4183-8ee1-dc7ba1474414",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct1_start = ct1m - (3*0.01)\n",
    "ct1_end = ct1m + (3*0.01)\n",
    "ct2_start = ct2m - (3*0.01)\n",
    "ct2_end = ct2m + (3*0.01)\n",
    "\n",
    "arl1, arl2, ct1m, ct2m = optimize_PAs(ct1_start, ct1_end, 0.001, py_env, 5000)\n",
    "ar_max = np.amax(arl1)\n",
    "max_index = arl1.index(ar_max)\n",
    "low = max_index - 5\n",
    "high = max_index + 5\n",
    "print('Range of high ARs after 2nd run: ', arl1[low:high])\n",
    "print('CT of center Value: ', ct1m)\n",
    "\n",
    "arl1, arl2, ct1m, ct2m = optimize_PAs(ct2_start, ct2_end, 0.001, py_env, 5000)\n",
    "ar_max = np.amax(arl2)\n",
    "max_index = arl2.index(ar_max)\n",
    "low = max_index - 5\n",
    "high = max_index + 5\n",
    "print('Range of high ARs for PA 2: ', arl2[low:high])\n",
    "print('CT of center Value: ', ct2m)\n",
    "    \n",
    "ar_max = np.amax(arl1)\n",
    "max_index = arl1.index(ar_max)\n",
    "low = max_index - 5\n",
    "high = max_index + 5\n",
    "print('Range of high ARs after third run: ', arl1[low:high])\n",
    "print('CT of center Value after third run: ', ct1m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ede3bd-fe05-4b85-a2c7-9254bfdba176",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_max = np.amax(arl1)\n",
    "max_index = arl1.index(ar_max)\n",
    "low = max_index - 10\n",
    "high = max_index + 10\n",
    "print('Range of high ARs after third run: ', arl1[low:high])\n",
    "print('CT of center Value after third run: ', ct1m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597e62a0-5cc1-4d38-9fba-aa68892485f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
