{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Phase Environment implemented according to scratch notes from call on 12/11/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import copy\n",
    "import random\n",
    "from scipy.stats import poisson\n",
    "from scipy.stats import geom\n",
    "from scipy.stats import hypergeom\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "from tf_agents.environments import py_environment\n",
    "from tf_agents.specs import BoundedArraySpec\n",
    "from tf_agents.trajectories.time_step import StepType\n",
    "from tf_agents.trajectories.time_step import TimeStep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation\n",
    "Env_P1 is a class that represents an epidemic with two herds.  \n",
    "\n",
    "<img src=\"Sketch.jpeg\"\n",
    "     alt=\"Env_P1 Sketch\"\n",
    "     style=\"float: left; margin-right: 8px;\" />\n",
    "## Variables:  \n",
    "The action $\\in \\mathbb{R}^4$ is a vector $(\\tau_1, \\tau_2, s_1, s_2)$.  \n",
    "$\\tau_i$ are the number of tests to be done in herd $i$.  \n",
    "$s_i \\in \\{0,1\\}$ determine whether a herd is to be completely replaced by healthy members.  \n",
    "$S_i$ is the number of susceptible herd members (subjects) of herd $i$, $i \\in {0,1}$.  \n",
    "$I_i$ is the number of infectious subjects of herd $i$, $i \\in {1,2}$.  \n",
    "$g$ is a small recovery probability.  \n",
    "$q$ is a small infection probability.  \n",
    "$B_i' = min(B_i,|S_i|-1)$ with $B_i = \\sum_{I_i} A$ and $A \\sim Poi(0.01)$, is the number of Susceptibles moving to Infectious per time step for herd $i$, $i \\in {1,2}$.  \n",
    "## State  \n",
    "The state contains two arrays of size six. \n",
    "state[0] is the observation shown to the agent.  \n",
    "The observation are testresults for each herd $(\\mu_i, x^i_0, x^i_1)$.  \n",
    "$\\mu_i$ shows the number of time steps since the test has been done.  \n",
    "$x^i_0$ and $x^i_1$ correspond to negative and positive testresults respectively.  \n",
    "\n",
    "state[1] instead contains the internal information about both herds.  \n",
    "state[1][i] shows the population size for herd i.  \n",
    "state[1][i+2] shows the total number of infected subjects for herd i.  \n",
    "## Reward  \n",
    "Reward calculation respects costs for tests and herd replacement.  \n",
    "Let $R$ be the current reward (starts at zero). Then each time step:  \n",
    "\n",
    "$R - \\tau_i * c + 1_{\\tau_i} * cprime, \\forall i \\in \\{0,1\\}$,  \n",
    "$R - s_i * state[1][i] * e, \\forall i \\in \\{0,1\\}$. \n",
    "  \n",
    "Here, $c$, $cprime > c$ and $e$ are constants.  \n",
    "Also, reduces reward by number of infectious:  \n",
    "\n",
    "$R - state[1][i+2], \\forall i \\in \\{0,1\\}$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Env_P1(py_environment.PyEnvironment):\n",
    "    def __init__(self,\n",
    "                population_herd1 = 200,\n",
    "                population_herd2 = 50,\n",
    "                exchanged_members = 5,\n",
    "                weeks_until_exchange = 4,\n",
    "                rand_recovery_prob = 0.005,\n",
    "                rand_infection_prob = 0.01,\n",
    "                ):\n",
    "        super(Env_P1, self).__init__()\n",
    "        self._state = None\n",
    "        self._discount = np.float32(1)\n",
    "        self._time = 0\n",
    "        self._episode_length = 0\n",
    "        self._tests = []\n",
    "        self._reward = np.float32(0)\n",
    "        self._c_tests = 1    #cost for each test\n",
    "        self._c_prime_tests = 50    #organizational costs tests\n",
    "        self._e_removed = 10    #individual replacement cost\n",
    "        self._weeks_until_testresults = 3\n",
    "        self._population_herd1 = population_herd1\n",
    "        self._population_herd2 = population_herd2\n",
    "        self._exchanged_members = exchanged_members    #k from scrapsheet\n",
    "        self._weeks_until_exchange = weeks_until_exchange    #T from scrapsheet\n",
    "        self._rand_recovery_prob = rand_recovery_prob    #g from scrapsheet\n",
    "        self._rand_infection_prob = rand_infection_prob    #q from scrapsheet\n",
    "    \n",
    "    def action_spec(self):\n",
    "        #Actions for: number of subjects to be tested h1, h2. number of subjects to be eliminated h1, h2\n",
    "        return BoundedArraySpec((1,4), np.float32, minimum=0, maximum=1)\n",
    "    \n",
    "    \n",
    "    def observation_spec(self):\n",
    "        # tau, x0, x1 for both herds\n",
    "        return BoundedArraySpec((1,6), np.int32, minimum=0, maximum=2**20)\n",
    "    \n",
    "    \n",
    "    def _reset(self):\n",
    "        '''\n",
    "        State consists of actual state of each herd (population and infected, state[1]),\n",
    "        and observation the agent gets to see (state[0]).\n",
    "        state[0] contains:\n",
    "        number of steps since test has taken place,\n",
    "        number of positive tests,\n",
    "        number of negative tests\n",
    "        for each herd.  \n",
    "        '''\n",
    "        self._state = np.zeros((2,6), np.int32)\n",
    "        initial_infected_h1 = np.random.randint(low = 1, high = (self._population_herd1/8))\n",
    "        self._time = 0\n",
    "        self._reward = np.float32(0)\n",
    "        self._episode_length = geom.rvs(p = 1/270)\n",
    "        self._state[1][3] = 0    #infected h2\n",
    "        self._state[1][2] = initial_infected_h1    #infected h1\n",
    "        self._state[1][1] = self._population_herd2\n",
    "        self._state[1][0] = self._population_herd1\n",
    "        self._state[0][5] = 0    #x1 tested pos h2\n",
    "        self._state[0][4] = 0    #x0 tested neg h2\n",
    "        self._state[0][3] = 0    #tau time since test h2\n",
    "        self._state[0][2] = 0    #x1 tested pos h1\n",
    "        self._state[0][1] = 0    #x0 tested neg h1\n",
    "        self._state[0][0] = 0    #tau time since test h1\n",
    "        observation = np.zeros((1,6), np.int32)\n",
    "        observation[0] = self._state[0]\n",
    "        return TimeStep(StepType.FIRST, reward=self._reward,\n",
    "                    discount=self._discount, observation = observation)\n",
    "    \n",
    "    def _test(self, herd = -1, num_tests = 0):\n",
    "        '''\n",
    "        Randomly draws (without returning) num_tests subjects of a herd,\n",
    "        then tests whether they are infected or not before returning testresults.\n",
    "        '''\n",
    "        assert self._state[1][herd] >= num_tests, \"More tests than herd members.\"\n",
    "        if herd >= 0 and num_tests > 0:\n",
    "            test_out = hypergeom.rvs(M = self._state[1][herd], n = self._state[1][herd+2], N = int(num_tests), size = 1)\n",
    "            testresults = np.zeros(3, np.int32)\n",
    "            testresults[1] = num_tests - test_out #negative tests\n",
    "            testresults[2] = test_out #positive tests\n",
    "            return testresults\n",
    "        else:\n",
    "            return np.zeros(3, np.int32)\n",
    "        \n",
    "    def _transfer(self, origin_herd = -1, target_herd = -1):\n",
    "        ''' \n",
    "        Each self._weeks_until_exchange weeks, transfers subjects \n",
    "        from origin_herd to target_herd by randomly drawing (without return)\n",
    "        self._exchanged_members subjects from all subjects of origin_herd.\n",
    "        returns numbers of infected transfers and susceptible transfers.'''\n",
    "        #failsafe for k>n?\n",
    "        assert self._state[1][origin_herd] > self._exchanged_members, \"Population in origin herd too low.\"\n",
    "        if origin_herd >= 0 and target_herd >=0 and self._time % self._weeks_until_exchange == 0:\n",
    "            infected_transfers = hypergeom.rvs(M = self._state[1][origin_herd], \n",
    "                                                 n = self._state[1][origin_herd+2], N = self._exchanged_members, size = 1)\n",
    "            susceptible_transfers = self._exchanged_members - infected_transfers\n",
    "            return np.array([susceptible_transfers, infected_transfers])    \n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def _model(self, action: np.ndarray, s1 = False, s2 = False):\n",
    "        '''\n",
    "        Completes one time step in a herd (i.e. excluding transfers and tests).\n",
    "        In f(x), samples new infections from poisson dist with lambda = 0.6,\n",
    "        also considers spontaneous infection and recovery factors.\n",
    "        Then, depending on whether a herd is to be replaced by healthy subjects (action),\n",
    "        calls f(x) or simply replaces all subjects by healthy subjects for each herd.\n",
    "        '''\n",
    "        \n",
    "        initial_state = self._state[1]\n",
    "        #Model for one herd\n",
    "        def f(x):\n",
    "            s_to_i = 0\n",
    "            for i in range (0, round(x[1])):\n",
    "                s_to_i += poisson.rvs(0.01)\n",
    "            s_to_i = round(min(s_to_i, x[0]))\n",
    "            dsdt = x[0] - s_to_i - round(self._rand_infection_prob * x[0]) + \n",
    "                                    round(self._rand_recovery_prob * x[1])\n",
    "            didt = x[1] + s_to_i + round(self._rand_infection_prob * x[0]) - \n",
    "                                    round(self._rand_recovery_prob * x[1])\n",
    "            return np.array([dsdt, didt])\n",
    "        \n",
    "        #One step for each herd\n",
    "        if s1:\n",
    "            initial_state_h2 = [self._state[1][1]-self._state[1][3], self._state[1][3]]\n",
    "            S1, I1 = [self._state[1][0], 0]\n",
    "            S2, I2 = f(x = initial_state_h2)\n",
    "        elif s2: \n",
    "            initial_state_h1 = [self._state[1][0]-self._state[1][2], self._state[1][2]]\n",
    "            S1, I1 = f(x = initial_state_h1)\n",
    "            S2, I2 = [self._state[1][1], 0]\n",
    "        else:\n",
    "            initial_state_h1 = [self._state[1][0]-self._state[1][2], self._state[1][2]]\n",
    "            initial_state_h2 = [self._state[1][1]-self._state[1][3], self._state[1][3]]\n",
    "            S1, I1 = f(x = initial_state_h1)\n",
    "            S2, I2 = f(x = initial_state_h2)\n",
    "        return np.array([S1+I1, S2+I2, I1, I2])\n",
    "    \n",
    "    def _reward_func(self, action: np.ndarray):\n",
    "        '''\n",
    "        Calculates and returns reward.\n",
    "        R -= tau_i * C + Indicator_i * C_prime\n",
    "        Where tau_i is number of tests in each herd, \n",
    "        Indicator_i is whether tau_i > 0 and C < C_prime.\n",
    "        R -= s_i * population_herd_i * replacement_cost\n",
    "        Where s_i is indicator for whether a herd was replaced by healthy subjects\n",
    "        and replacement_cost is a constant representing the cost of replacing a single subject.\n",
    "        '''\n",
    "        tau_1 = np.round(action[0][0] * self._state[1][0]) \n",
    "        tau_2 = np.round(action[0][1] * self._state[1][1])\n",
    "        indicator_1, indicator_2, s1, s2 = 0, 0, 0, 0 \n",
    "        if action[0][2] > 1/2 and action[0][3] <= 1/2:\n",
    "            s1 = 1\n",
    "        if action[0][3] > 1/2 and action[0][2] <= 1/2:\n",
    "            s2 = 1\n",
    "        if tau_1 > 0:\n",
    "            indicator_1 = 1\n",
    "        if tau_2 > 0:\n",
    "            indicator_2 = 1\n",
    "        self._reward -= self._discount * (tau_1 * self._c_tests + indicator_1 * self._c_prime_tests)\n",
    "        self._reward -= self._discount * (tau_2 * self._c_tests + indicator_2 * self._c_prime_tests)\n",
    "        self._reward -= self._discount * (s1 * self._state[1][0] * self._e_removed + \n",
    "                                          s2 * self._state[1][1] * self._e_removed)\n",
    "        self._reward -= self._discount * (self._state[1][2] + self._state[1][3])\n",
    "        return self._reward\n",
    "    \n",
    "    def _step(self, action: np.ndarray):\n",
    "        '''\n",
    "        Step completes one time step in the environment.\n",
    "        First, transfers subjects if time interval dictates it.\n",
    "        Then, calls model(action) to complete a time step in each herd.\n",
    "        Afterwards, tests subjects if action dictates it and outputs testresults\n",
    "        if time for testing has been concluded.\n",
    "        Finally, calculates reward and returns a Time_Step object.\n",
    "        TimeStep(StepType.MID, reward=reward, discount=self._discount, observation=[self._state[0]])\n",
    "        \n",
    "        TODOS: Check chronology\n",
    "        '''\n",
    "        if self._current_time_step.is_last():\n",
    "            return self._reset()\n",
    "        \n",
    "        self._time += 1\n",
    "        origin_herd = 0\n",
    "        target_herd = 1\n",
    "        transfers = self._transfer(origin_herd = origin_herd, target_herd = target_herd)\n",
    "        back_transfers = self._transfer(origin_herd = target_herd, target_herd = origin_herd)\n",
    "        if transfers is not None:\n",
    "            self._state[1][origin_herd] = self._state[1][origin_herd] - transfers[0] - transfers[1] + \n",
    "                                            back_transfers[0] + back_transfers[1]\n",
    "            self._state[1][target_herd] = self._state[1][target_herd] + transfers[0] + transfers[1] - \n",
    "                                            back_transfers[0] - back_transfers[1]\n",
    "            self._state[1][origin_herd+2] = self._state[1][origin_herd+2] - transfers[1] + back_transfers[1]\n",
    "            self._state[1][target_herd+2] = self._state[1][target_herd+2] + transfers[1] - back_transfers[1]\n",
    "            \n",
    "        #interpreting actions\n",
    "        num_test_h1 = np.round(action[0][0] * self._state[1][0])\n",
    "        num_test_h2 = np.round(action[0][1] * self._state[1][1])\n",
    "        \n",
    "        rem_h1 = False\n",
    "        rem_h2 = False\n",
    "        if action[0][2] > 1/2 and action[0][3] <= 1/2:\n",
    "            rem_h1 = True\n",
    "        if action[0][3] > 1/2 and action[0][2] <= 1/2:\n",
    "            rem_h2 = True\n",
    "            \n",
    "        #Model should make a step in between transfer and test\n",
    "        self._state[1][0:4] = self._model(action, s1 = rem_h1, s2 = rem_h2)\n",
    "        #Testing \n",
    "        self._tests.append(self._test(herd = 0, num_tests = num_test_h1))\n",
    "        self._tests.append(self._test(herd = 1, num_tests = num_test_h2))\n",
    "        \n",
    "        for i in range (0, np.ma.size(self._tests, axis = 0)):\n",
    "            if self._tests[i][0] == self._weeks_until_testresults:\n",
    "                self._state[0][5] = self._tests[i+1][2]    #x1 tested pos h2\n",
    "                self._state[0][4] = self._tests[i+1][1]    #x0 tested neg h2\n",
    "                self._state[0][3] = self._weeks_until_testresults    \n",
    "                self._state[0][2] = self._tests[i][2]    #x1 tested pos h1\n",
    "                self._state[0][1] = self._tests[i][1]    #x0 tested neg h1\n",
    "                self._state[0][0] = self._weeks_until_testresults\n",
    "                self._tests.pop(i)\n",
    "                self._tests.pop(i)\n",
    "                break\n",
    "        for i in range (0, np.ma.size(self._tests, axis = 0)):\n",
    "            self._tests[i][0] += 1 \n",
    "            \n",
    "        #Reward function\n",
    "        reward = np.float32(self._reward_func(action))\n",
    "        \n",
    "        #debugging\n",
    "        if self._time % 50 == 0:\n",
    "            print(self._state)\n",
    "            \n",
    "        #output\n",
    "        if self._time == self._episode_length:\n",
    "            print(\"Reset Reached\")\n",
    "            Final_Step = TimeStep(StepType.LAST, reward=reward, discount=self._discount, observation=np.array([self._state[0]]))\n",
    "            self._reset()\n",
    "            return Final_Step\n",
    "            \n",
    "        else:\n",
    "            return TimeStep(StepType.MID, reward=reward, discount=self._discount, observation=np.array([self._state[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset Reached\n",
      "[[  3  26  34   3  11   4]\n",
      " [200  50 105  15   0   0]]\n",
      "Reset Reached\n",
      "[[  3  38  22   3  12   3]\n",
      " [200  50  81  12   0   0]]\n",
      "[[  3  17  43   3   7   8]\n",
      " [200  50 131  28   0   0]]\n",
      "Reset Reached\n",
      "Reset Reached\n",
      "[[  3  34  26   3   9   6]\n",
      " [200  50 104  22   0   0]]\n",
      "[[  3  11  49   3   3  12]\n",
      " [200  50 155  41   0   0]]\n",
      "[[  3   5  55   3   0  15]\n",
      " [200  50 196  50   0   0]]\n",
      "[[  3   1  59   3   0  15]\n",
      " [200  50 199  50   0   0]]\n",
      "[[  3   1  59   3   0  15]\n",
      " [200  50 199  50   0   0]]\n",
      "[[  3   0  60   3   0  15]\n",
      " [200  50 199  50   0   0]]\n",
      "[[  3   1  59   3   0  15]\n",
      " [200  50 199  50   0   0]]\n",
      "[[  3   0  60   3   0  15]\n",
      " [200  50 199  50   0   0]]\n",
      "Reset Reached\n",
      "[[  3  34  26   3  12   3]\n",
      " [200  50 102  14   0   0]]\n",
      "Reset Reached\n",
      "[[  3  35  25   3  10   5]\n",
      " [200  50  84  18   0   0]]\n",
      "[[  3  15  45   3   2  13]\n",
      " [200  50 134  40   0   0]]\n",
      "[[  3   3  57   3   0  15]\n",
      " [200  50 185  48   0   0]]\n",
      "[[  3   1  59   3   0  15]\n",
      " [200  50 199  50   0   0]]\n",
      "[[  3   1  59   3   0  15]\n",
      " [200  50 199  50   0   0]]\n"
     ]
    }
   ],
   "source": [
    "env = Env_P1()\n",
    "env.reset()\n",
    "for i in range (1,1000):\n",
    "    env.step([[0.3, 0.3, 1, 1]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
