{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0042ecb-949c-4ae2-8abf-bf73fc7f5ddc",
   "metadata": {},
   "source": [
    "## Policy Playground  \n",
    "This is code for loading and testing saved policies.  \n",
    "Before use, please edit the path to the environment folder.  \n",
    "For further instructions, please visit the \"Policies\" section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3099cf-95c3-4f79-939d-bf26e472ba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to environment folder\n",
    "import sys\n",
    "sys.path.insert(1, '/home/jovyan/Masterarbeit/reinforce-one/Environments')\n",
    "sys.path.insert(1, '/home/jovyan/Masterarbeit/reinforce-one/Environments/Variations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639362be-d4a2-46c2-91b5-697a991865c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.policies import scripted_py_policy\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "matplotlib.rcParams.update({'font.size': 17})\n",
    "#plt.ioff() \n",
    "\n",
    "#from RNN_Env_P2 import Env_P2_N\n",
    "from EE0 import EE0\n",
    "from EE0_5 import EE0_5\n",
    "from EE1 import EE1\n",
    "from EE0_NT import EE0_NT\n",
    "from EE0_A import EE0_A\n",
    "from EE1_A import EE1_A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84609753-7810-4bbb-a7cc-d4e6e54a01e1",
   "metadata": {},
   "source": [
    "### Policies\n",
    "\n",
    "The policies that are loaded by default are the best policies for each configuration in every environment.  \n",
    "The folder they are saved in is named after the iteration where they were evaluated and the average return achieved.  \n",
    "To test these policies, complete the following steps:  \n",
    "- Set \"test_pol\" to any of the loaded policies.\n",
    "- Set \"py_env\" (and the env parameters) to the environment variant \"test_pol\" was trained in.\n",
    "- Edit \"act_plots\" variable if no plots are needed.\n",
    "- Run all cells.  \n",
    "\n",
    "Results can be viewed in the last cell.  \n",
    "Note that plots and cost calculation do not work correctly for P1_A without plot and testing function edits.  \n",
    "Also, for correct cost calculation in EE0_NT please set all test costs to 0.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21752fdb-d0b8-4f52-9ce6-816cd725842a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Parameters \n",
    "max_episode_length=1000\n",
    "num_herds = 2\n",
    "total_population = 300\n",
    "test_costs_env = 0.01    # 0 in EE0_NT\n",
    "test_org_env = 1.    # 0 in EE0_NT\n",
    "cull_cost = (1/num_herds)\n",
    "# Test policy actross num_episodes episodes\n",
    "num_episodes = 1000\n",
    "\n",
    "# Best policies in EE0\n",
    "P1 = tf.compat.v2.saved_model.load('Runs/RDDPG/R19/126000_-5.508191')\n",
    "P2 = tf.compat.v2.saved_model.load('Runs/APPO/R15/28900_-5.7956944')\n",
    "P3 = tf.compat.v2.saved_model.load('Runs/ADDPG/R20/89000_-6.7822328')\n",
    "P4 = tf.compat.v2.saved_model.load('Runs/RPPO/R19/24000_-7.843697')\n",
    "\n",
    "# Best policies in EE0_NT\n",
    "P1_NT = tf.compat.v2.saved_model.load('Runs/Variants/EE0_NT/R2/88000_-3.4844654')\n",
    "ADDPG_NT_P1 = tf.compat.v2.saved_model.load('Runs/Variants/EE0_NT/ANN_DDPG/R15/326900')\n",
    "RDPG_NT_P1 = tf.compat.v2.saved_model.load('Runs/Variants/EE0_NT/RNN_DDPG/R1/49000_-3.3300657')\n",
    "# Best policy of ANN PPO in EE0_A\n",
    "P1_A = tf.compat.v2.saved_model.load('Runs/Variants/EE0_A/R3/69000_-4.8970075')\n",
    "# Best policy of ANN PPO in EE1\n",
    "P1_EE1 = tf.compat.v2.saved_model.load('Runs/Variants/EE1/R2/33000_-14.067305')\n",
    "# # Best policy of ANN PPO in EE0_5\n",
    "P1_EE0_5 = tf.compat.v2.saved_model.load('Runs/Variants/EE0_5/14000_-7.7829237')\n",
    "\n",
    "\n",
    "# Policy to be tested\n",
    "test_pol = P1\n",
    "\n",
    "# Action plots\n",
    "act_plots = True\n",
    "\n",
    "# Environment the policy was trained in\n",
    "py_env = EE0(num_herds = num_herds, total_population = total_population, fix_episode_length = True, average_episode_length = 200)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(py_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da76185-7053-4a9c-a158-d4126e790bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_actions_and_states(action_list, inf_list, tests_list):\n",
    "        if (num_herds != 2):\n",
    "            print('Plotting only works for 2 herds.')\n",
    "            return None\n",
    "        t = np.linspace(0, len(action_list), num=len(action_list))\n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.title('(A) Tests over Time')\n",
    "        plt.xlabel('Time Step')\n",
    "        plt.ylabel('Percentage of Herd')\n",
    "        plt.ylim(-0.01, 1.01)\n",
    "        #p3.set_yscale('log')\n",
    "        n_tests_h1, n_tests_h2, replace_h1, replace_h2, inf_h1, inf_h2 = [], [], [], [], [], []\n",
    "        tests_h1, tests_h2 = [],[]\n",
    "        for i in range(len(action_list)):\n",
    "            n_tests_h1.append(action_list[i][0])\n",
    "            n_tests_h2.append(action_list[i][1])\n",
    "            '''  \n",
    "            #For EE1_A:\n",
    "            if action_list[i][0] < (1/3):\n",
    "                n_tests_h1.append(0)\n",
    "            elif action_list[i][0] < (2/3):\n",
    "                n_tests_h1.append(0.5)\n",
    "            else: \n",
    "                n_tests_h1.append(1)\n",
    "            if action_list[i][1] < (1/3):\n",
    "                n_tests_h2.append(0)\n",
    "            elif action_list[i][1] < (2/3):\n",
    "                n_tests_h2.append(0.5)\n",
    "            else: \n",
    "                n_tests_h2.append(1)\n",
    "            '''\n",
    "\n",
    "            replace_h1.append(action_list[i][2])\n",
    "            replace_h2.append(action_list[i][3])\n",
    "            inf_h1.append(inf_list[i][0])\n",
    "            inf_h2.append(inf_list[i][1])\n",
    "            tests_h1.append(tests_list[i][0])\n",
    "            tests_h2.append(tests_list[i][1])            \n",
    "        plt.plot(t, n_tests_h1, color='fuchsia', label = 'Number of Tests Herd 1', marker = '', linestyle = '-', alpha=0.7)\n",
    "        plt.plot(t, n_tests_h2, color='mediumblue', label = 'Number of Tests Herd 2', marker = '', linestyle = '-', alpha=0.7)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.title('(B) Correlation of Testresults and Culls')\n",
    "        plt.xlabel('Time Step')\n",
    "        plt.ylabel('Percentage of Tests')\n",
    "        ymax_p3 = min(1.1, max(max(inf_h1)+0.01,max(inf_h2)+0.01))\n",
    "        plt.ylim(-0.01, ymax_p3+0.01)\n",
    "        plt.plot(t, inf_h1, color='fuchsia', label = 'Positive Tests Herd 1', marker = '', linestyle = '-', alpha=0.7)\n",
    "        plt.plot(t, inf_h2, color='mediumblue', label = 'Positive Tests Herd 2', marker = '', linestyle = '-', alpha=0.7)\n",
    "        first = True\n",
    "        second = True\n",
    "        for j in range(0,len(replace_h1)):\n",
    "            if first:\n",
    "                if replace_h1[j] == 1:\n",
    "                    plt.scatter(x=j, y=inf_h1[j], s = 20+tests_h1[j]*300, c='limegreen', marker = 'o', edgecolors='black', label = 'Culls Herd 1')\n",
    "                    if(tests_h1[j] > 0.):\n",
    "                        plt.annotate(str(round(tests_h1[j],2)),(j+3, inf_h1[j]))\n",
    "                    first = False\n",
    "            else: \n",
    "                if replace_h1[j] == 1:\n",
    "                    plt.scatter(x=j, y=inf_h1[j], s = 20+tests_h1[j]*300, c='limegreen', marker = 'o', edgecolors='black')\n",
    "                    if(tests_h1[j] > 0.):\n",
    "                        plt.annotate(str(round(tests_h1[j],2)),(j+3, inf_h1[j]))\n",
    "            if second:\n",
    "                if replace_h2[j] == 1:\n",
    "                    plt.scatter(x=j, y=inf_h2[j], s = 20+tests_h2[j]*300, c='yellow', marker = 'o',edgecolors='black', label = 'Culls Herd 2')\n",
    "                    if(tests_h1[j] > 0.):\n",
    "                        plt.annotate(str(round(tests_h2[j],2)),(j+3, inf_h2[j]))\n",
    "                    second = False\n",
    "            else: \n",
    "                if replace_h2[j] == 1:\n",
    "                    plt.scatter(x=j, y=inf_h2[j], s = 20+tests_h2[j]*300, c='yellow', marker = 'o',edgecolors='black')\n",
    "                    if(tests_h1[j] > 0.):\n",
    "                        plt.annotate(str(round(tests_h2[j],2)),(j+3, inf_h2[j]))\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c25e48-fa57-46e6-9e8d-32c5a22b12ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_policy(env, policy, num_episodes=50, num_herds = 2, create_plot = False):\n",
    "    if isinstance(env, tf_py_environment.TFPyEnvironment):\n",
    "        returns_arr = []\n",
    "        culls_arr = []\n",
    "        tests_arr = []\n",
    "        actions = []\n",
    "        infectious = []\n",
    "        perc_tested = []\n",
    "        cull_costs_arr = []\n",
    "        test_costs_arr = []\n",
    "        hpop = total_population/num_herds\n",
    "        if env.action_spec().shape[0] == num_herds:\n",
    "            raise ValueError('Only for environments with tests and culls.')\n",
    "\n",
    "        for e in range(num_episodes):\n",
    "            time_step = env.reset()\n",
    "            if isinstance(policy, scripted_py_policy.ScriptedPyPolicy):\n",
    "                raise ValueError('Only for agent policies.')\n",
    "            else:\n",
    "                policy_state = policy.get_initial_state(env.batch_size)\n",
    "            episode_return = 0.0\n",
    "            ep_tests = 0\n",
    "            ep_culls = 0\n",
    "            ep_tc = 0\n",
    "            ep_cc = 0\n",
    "            \n",
    "            while not time_step.is_last():\n",
    "                action_step = policy.action(time_step, policy_state)\n",
    "                \n",
    "                # Count total number of culls and cull costs\n",
    "                for j in range (num_herds, num_herds*2):\n",
    "                    if action_step.action[0][j] >= 0.5:\n",
    "                        ep_cc += -cull_cost\n",
    "                        ep_culls += 1\n",
    "                        \n",
    "                # Count number of steps where tests were done for each herd\n",
    "                for k in range (0, num_herds):\n",
    "                    if ((action_step.action[0][k]*hpop) >= 0.5):\n",
    "                        ep_tests += 1\n",
    "                        act = max(0, min(hpop, (np.rint(action_step.action[0][k]*hpop))))\n",
    "                        test_c =  -(test_org_env + (act*test_costs_env)) / total_population\n",
    "                        ep_tc += test_c\n",
    "\n",
    "                        '''     \n",
    "                        # For EE1_A:\n",
    "                        if (action_step.action[0][k] < 1/3):\n",
    "                            ep_tc += 0\n",
    "                        elif (action_step.action[0][k] < 2/3):\n",
    "                            act = max(0, min(hpop, (np.rint(0.5*hpop))))\n",
    "                            test_c =  -(test_org_env + (act*test_costs_env)) / total_population\n",
    "                            ep_tc += test_c\n",
    "                            ep_tests += 1\n",
    "                        else: \n",
    "                            act = max(0, min(hpop, (np.rint(1*hpop))))\n",
    "                            test_c =  -(test_org_env + (act*test_costs_env)) / total_population\n",
    "                            ep_tc += test_c\n",
    "                            ep_tests += 1\n",
    "\n",
    "                        '''\n",
    "\n",
    "                            \n",
    "                # Save actions and states for one episode\n",
    "                if e == np.int32(num_episodes/2):\n",
    "                    act = np.zeros(np.size(action_step.action[0]), np.float32)\n",
    "                    act[0] = action_step.action[0][0]\n",
    "                    act[1] = action_step.action[0][1]\n",
    "                    for c in range(num_herds, num_herds*2):\n",
    "                        if action_step.action[0][c] >= 0.5:\n",
    "                            act[c] = 1.\n",
    "                        else:\n",
    "                            act[c] = 0.\n",
    "                    actions.append(act)\n",
    "                    inf_percentages = np.zeros(num_herds, np.float32)\n",
    "                    perc_test = np.zeros(num_herds, np.float32)\n",
    "                    # take observation instead of actual state, since get_state doesnt work\n",
    "                    state = time_step.observation[0]\n",
    "                    for d in range (0, num_herds):\n",
    "                        # Assumes Env has observations as in Env_TSLC, otherwise d*3\n",
    "                        inf_percentages[d] = (state[(d*4)+2])\n",
    "                        perc_test[d] = state[(d*4)+1]\n",
    "                    infectious.append(inf_percentages)\n",
    "                    perc_tested.append(perc_test)\n",
    "                    \n",
    "                policy_state = action_step.state\n",
    "                time_step = env.step(action_step.action)\n",
    "                episode_return += time_step.reward\n",
    "            \n",
    "            returns_arr.append(episode_return) \n",
    "            culls_arr.append(ep_culls)\n",
    "            tests_arr.append(ep_tests)\n",
    "            cull_costs_arr.append(ep_cc)\n",
    "            test_costs_arr.append(ep_tc)\n",
    "            \n",
    "        if create_plot:\n",
    "            plot_actions_and_states(actions, infectious, perc_tested)\n",
    "        avg_return = np.average(returns_arr)\n",
    "        variance = np.var(returns_arr)\n",
    "        stddev =  np.std(returns_arr)\n",
    "        avg_culls = np.average(culls_arr) \n",
    "        avg_tests = np.average(tests_arr)\n",
    "        avg_cull_costs = np.average(cull_costs_arr)\n",
    "        avg_test_costs = np.average(test_costs_arr)\n",
    "        return avg_return, avg_culls, avg_tests, variance, stddev, avg_cull_costs, avg_test_costs\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a816d7-c663-4670-9ebc-a0a128721bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    " def plot_n_actions(action_list, environment, num_herds):\n",
    "        # only for envs with 2 actions per herd per step\n",
    "        colors = ['b', 'g', 'r', 'y', 'k']\n",
    "        t = np.linspace(0, len(action_list), num=len(action_list))\n",
    "        fig, (p1,p2) = plt.subplots(1, 2, figsize=(15,7))\n",
    "        fig.suptitle('Actions over time')\n",
    "        p1.set_title('Tests over Time')\n",
    "        p1.set_xlabel('Time steps')\n",
    "        p1.set_ylabel('Number of Tests')\n",
    "        p1.set_ylim(-0.1, 1.1)\n",
    "        p2.set_title('Culls over Time')\n",
    "        p2.set_xlabel('Time')\n",
    "        p2.set_ylabel('Positive tests')\n",
    "        p2.set_ylim(-0.1, 1.1) \n",
    "        tests, replace = [], []\n",
    "        for i in range (len(action_list)):\n",
    "            temp_tests = []\n",
    "            temp_replace = []\n",
    "            for j in range (0, num_herds):\n",
    "                temp_tests.append(action_list[i][j])\n",
    "                temp_replace.append(action_list[i][j+num_herds])\n",
    "            tests.append(temp_tests)\n",
    "            replace.append(temp_replace)\n",
    "        tests = np.array(tests)\n",
    "        replace = np.array(replace)\n",
    "        for k in range (0, num_herds):\n",
    "            tmp_label = 'Herd ' + str(k+1)\n",
    "            p1.plot(t, tests[:,k], color=colors[(k % len(colors))], label = tmp_label, marker = '', linestyle = '-',alpha=0.7)\n",
    "            p2.plot(t, replace[:,k], color=colors[(k % len(colors))], label = tmp_label, marker = '', linestyle = '-',alpha=0.7)\n",
    "            \n",
    "        p1.legend()\n",
    "        p2.legend()\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723fb935-d524-4d8d-8d8e-e9ed2645e059",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, cull, tests, var, std, cc, tc  = test_policy(eval_env, test_pol, num_episodes = num_episodes, num_herds = num_herds, create_plot = act_plots)\n",
    "print('Average Return: ', ret)\n",
    "print('Variance: ', var)\n",
    "print('Standard Deviation: ', std)\n",
    "print('Average Culls: ', cull)\n",
    "print('Average Cull Costs: ', cc)\n",
    "print('Average Tests: ', tests)\n",
    "print('Average Test Costs: ', tc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
